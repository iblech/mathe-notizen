=== Ringe mit eindeutiger Primidealzerlegung

* Sei A ein Dedekindring. (Oder nur ein Integritätsbereich der Dimension <= 1,
  in dem jedes von Null verschiedene Ideal eine eindeutige Zerlegung in
  Primideale zulässt. Man kann das noch weiter abschwächen.)

  Seien p_1, ..., p_n von Null verschiedene und paarweise verschiedene Primideale.

  Gelte: prod_i p_i^(a_i) <= prod_i p_i^(b_i).

  Dann folgt a_i >= b_i für alle i.

  Denn angenommen, für ein solches i gilt a_i < b_i. Wegen der Eindeutigkeit
  der Primidealzerlegung finden wir dann ein Elemente pi aus p_i^(a_i) \ p_i^(b_i).

  Da die p_i paarweise koprim sind, sind auch beliebige Potenzen dieser Ideale
  paarweise koprim. Nach dem chinesischen Restsatz finden wir daher ein Element x mit

      x = pi modulo p_i^(b_i)
      x = 0  modulo p_j^(a_j) für j != i.

  Dieses x ist modulo allen p_j^(a_j) Null. Es liegt also im Schnitt dieser
  Ideale und, wegen der Koprimalität, auch im Produkt dieser Ideale. Nach
  Voraussetzung liegt es also im Produkt der p_j^(b_j) und insbesondere in
  p_i^(b_i). Also ist x gleich Null modulo p_i^(b_i). Aber das ist ein
  Widerspruch, denn x ist pi modulo p_i^(b_i) und pi ist nicht Null modulo
  p_i^(b_i).

* Konsequenzen daraus sind:

  1. a <= b  <==>  a^m <= b^m.
  2. Die erwarteten Rechenregeln für Summe und Schnitt von Produkten von
     Primidealen (wie bei ggT und kgV von Zahlen).


=== Ringe mit eindeutiger Zerlegung in Irreduzible & Co.

* Sei c regulär. Existiere ggT(ac,bc). Dann ggT(a,b) = ggT(ac,bc) / c.

* Sei c regulär. Existiere ggT(ac,bc). Dann gilt Euklids Lemma:

      Wenn a | bc und ggT(a,b) = 1, dann a | c.

  Beweis: a | ac und a | bc, also a | ggT(ac,bc) = ggT(a,b) c = c.

  http://math.stackexchange.com/questions/313345/does-euclid-lemma-hold-for-gcd-domains

* Euklids Lemma gilt ohne ggT-Existenz-Voraussetzung in folgender Form:

    Sei b regulär. Wenn a | bc und kgV(a,b) = ab, dann a | c.

  Beweis: a | bc und b | bc, also ab = kgV(a,b) | bc, also a | c.

* In ggT-Ringen sind dank Euklids Lemma irreduzible Elemente schon prim:

  Zunächst überlegt man sich, dass die einzigen Teiler eines irreduziblen
  Elements 1 und das Element selbst sind. Sei dann d | xy. Es ist ggT(d,x)
  ein Teiler von d, also gleich d oder gleich 1. Im ersten Fall folgt d | x.
  Im zweiten sind die Voraussetzungen von Euklids Lemma erfüllt, womit d | y
  folgt.

* Wenn wir einen UFD-Bereich als einen ggT-Bereich, in dem jedes reguläre
  Element eine Zerlegung in irreduzible Elemente zulässt, definieren dann haben
  wir:

  1. UFD-Bereich ==> ggT-Bereich (trivial)
  2. Jedes reguläre Element in einem UFD-Bereich besitzt eine eindeutige
     Zerlegung in irreduzible Elemente.
  3. Und falls wir prüfen können, ob gegebene irreduzible Elemente zueinander
     assoziiert sind (etwa in klassischer Logik): Dann ist ein
     Integritätsbereich, in dem jedes reguläre Element eine eindeutige
     Zerlegung in irreduzible Elemente besitzt, schon ein UFD-Bereich in
     unserem Sinn.
  4. Ein Integritätsbereich ist genau dann ein UFD-Bereich, wenn jedes
     reguläre Element eine eindeutige Zerlegung in irreduzible Elemente
     besitzt und die Assoziiertheit irreduzibler Elemente entscheidbar ist.

 http://mathoverflow.net/questions/151973/constructively-correct-notion-of-unique-factorization-domain


=== Diskrete Bewertungsbereiche

* Jedes Ideal in einem diskreten Bewertungsbereich ist von der Form

      m_k = { x in A | nu(x) >= k }

  für ein k >= 0 (k = infty erlaubt).

* m_{k+1} <= m_k.

* Wenn m_l <= m_k, dann l >= k. Denn: Wir können m_l = (x^l) und
  m_k = (x^k) schreiben. Somit x^l in m_k. Somit nu(x^l) = l >= k.

* Genau dann (a_i)_i = m_k, wenn min_i nu(a_i) = k.

  "<==": Habe (a_i)_i = m_l. Da alle a_i in m_k liegen, gilt somit m_l <= m_k.
  Also l >= k. Habe außerdem i0 mit nu(a_i0) = k. Trotzdem k >= l. Also k = l.

  "==>": Habe nu(a_i) >= k für alle i. Wenn für alle i ">" gelten würde, dann
  wäre (a_i)_i <= m_{k+1}. Aber das kann nicht sein.

  Direkt so: Sei (a_i)_i = (u). Wir wollen zeigen, dass nu(u) = min_i nu(a_i).
  Da u = sum_i f_i a_i, gilt nu(u) >= min_i nu(a_i). Da a_i = t_i u für jedes i,
  gilt nu(a_i) >= nu(u) für jedes i und damit insbesondere min_i nu(a_i) >= nu(u).

* Sei nu(a) >= n + 1 und nu(b) = n. Dann nu(a + b) = n.

  Dabei ist ">=" klar, wegen der Rechenregel von nu mit dem Minimum.

  Wenn ">" gelten würde, dann wäre

      nu(b) = nu((a + b) + (-a)) >= min { nu(a+b), nu(a) } >= n + 1.


=== Kommutierende Matrizen

* Kommutierende Matrizen lassen sich im Allgemeinen *nicht* simultan
  auf Jordanform bringen!

  http://math.stackexchange.com/questions/49378/simultaneous-jordanization


=== Klassifikation von Matrizen über Z

* Sei f(X) in Z[X] irreduzibel vom Grad n.

  Dann ist die Menge der (n x n)-Matrizen über Z mit charakteristischem Polynom
  gleich f(X) bis auf Ähnlichkeit isomorph zur Idealklassengruppe von Z[theta].

  Die Richtung "|-->" geht so: Finde zu so einer Matrix A einen Eigenvektor in
  Z[theta]^n zum Eigenwert theta (die Nullstellen von f(X) sind paarweise
  verschieden, finde den Eigenvektor zunächst in Q(theta)). Dann haben wir die
  Idealklasse [(Ideal, das von den Einträgen des Eigenvektors über Z erzeugt
  wird)].


=== Minimale freie Auflösungen

Sei S = k[x_0,...,x_n]. Habe S --> k durch Auswertung bei (0,...,0).

* Eine minimale freie Auflösung eines S-Moduls M ist eine
  endliche freie Auflösung, in der die Differentiale tensoriert mit k
  Null sind.

* Sei 0 --> F_* --> M --> 0 eine minimale freie Auflösung mit
  F_i = oplus_j S(-j)^{beta_ij}. Dann:

      beta_ij = dim_k Tor_i^S(k, M)_j  (Grad-j-Anteil)

  Um das einzusehen, einfach mit der gegebenen Auflösung die rechte Seite
  ausrechnen. Der dazu benötigte Komplex hat verschwindende Differentiale.

* Die Formel zeigt auch: F_i = 0 für i >= n + 2!
  Denn für k gibt es die Koszul-Auflösung, welche eine entsprechende Länge hat.

* https://tlovering.wordpress.com/2012/10/24/hilberts-syzygy-theorem-isnt-very-hard-to-prove/
  sagt: Eine freie Auflösung, in der man in jedem Schritt die Minimalzahl
  benötigter Erzeuger nimmt, ist minimal in diesem Sinn.


=== Erweiterung und Kontraktion von Idealen

* Sei A --> B ein Ringhomo und I ein Ideal von A. Dann gilt:

      sqrt(sqrt(I) B) = sqrt(I B).

* Sei I ein Ideal von A und J ein Ideal von B. Dann gilt:

      I B <= J    <===>    I <= A cap J.

* Die Idealerweiterung eines Radikalideals ist im Allgemeinen kein
  Radikalideal. Betrachte etwa die Erweiterung von (2), dem Ideal von Z,
  in Z[sqrt(2)]. In der Erweiterung liegt sqrt(2)^2 = 2, nicht aber sqrt(2)
  selbst (in der Erweiterung sind die Koeffizienten im gerade).

  Es stimmt schon, falls man zu Lokalisierungen des Basisrings hin erweitert.
  In diesem Fall ist sogar sqrt(I B) = sqrt(I) B.


=== Annihilator

* Ann A/I = I.

* Stets gilt (in klassischer Logik natürlich):

      supp(M) <= V(Ann M).

  Wenn M endlich erzeugt ist, gilt auch ">=".

  Zeige dazu für ein Primideal p:

      M_p != 0   (<)==>   Ann(M) <= p.

  "==>": Sei sM = 0. Angenommen, s nicht in p. Dann M_p = 0. Widerspruch.

  "<==": Angenommen M_p = 0. Dann existiert zu jedem x aus M ein s nicht in p
  mit sx = 0 in M. Da M endlich erzeugt ist, gibt es damit s_1 ... s_n nicht in p
  mit s_1 ... s_n M = 0, also s_1 ... s_n in Ann(M) <= p. Widerspruch.


=== Ein Primidealprinzip

* Lam, Reyes. A prime ideal principle in commutative algebra.
  https://math.berkeley.edu/~lam/html/JAlg-PIP.pdf

* Insbesondere ist ein Ideal, das maximal mit der Eigenschaft ist, nicht
  endlich erzeugt zu sein, prim. Direkter Beweis hier:
  http://math.stackexchange.com/questions/146884/an-ideal-that-is-maximal-among-non-finitely-generated-ideals-is-prime


=== Jacobsonsches Radikal

* Das jacobsonsche Radikal j ist der Schnitt über alle maximale Ideale.
  Klassisch gilt: j = { x | 1 - xy inv. für alle y }.

* Ein Ring heißt genau dann jacobsonsch, wenn jedes Primideal Schnitt
  von maximalen Idealen ist.

* Jede endlich erzeugte Algebra über einem (nicht notwendermaßen algebraisch
  abgeschlossenen) Körper ist jacobsonsch. Das sagt Hilberts Nullstellensatz.
  Siehe Götz/Wedhorn, Thm. 1.7, Seite 10.

* Ist S eine endlich erzeugte Algebra über einem jacobsonschen Ring R,
  so ist auch S jacobsonsch, Urbilder von maximalen Idealen sind wieder
  maximal und die zugehörigen Restklassenkörpererweiterungen sind endlich.
  http://stacks.math.columbia.edu/tag/00GB


=== Dualer Vektorraum

Sei V ein Vektorraum über einem Körper F und dim(V) = infty.
Dann dim(V^) > dim(V).

Das geht so (siehe http://math.stackexchange.com/a/35863/61604):
Sei d = dim(V), d^ = dim(V^). Dann zeige d^ >= |F|.

Somit |V^| = d' * |F| = max { d', |F| } = d'.

Also d' = |V^| = |F|^|d| > |d|, da |F| >= 2.

* Dabei verwendet: Ist W von Dimension a, so |W| = a * |F|.
  
  Das zeigt man so (wobei B eine Basis von W ist):

      |W| = |bigcup_{T <= B endlich} prod_T F|
          = sum_{T <= B endlich} |F|^|T|
          = sum_{T <= B endlich} |F|
          = |B| * |F| = a * |F|.

  Wie geht das genau?


=== Lokale Eigenschaften

Für mich bedeutet "lokal": bezüglich einer Zerlegung der Eins.
Eine Alternative ist "halmweise".

* Surjektivität ist eine lokale Eigenschaft.


=== Fitting-Ideale

* Das i-te Fitting-Ideal eines endlich präsentierten Moduls M
  mit Präsentationsmatrix A : R^a --> R^b ist das Ideal der (b-i)-Minoren von A.
  Es ist unabhängig von der Wahl der Präsentationsmatrix. Das sieht man so:
  (Nach Serre, Algebra)

  1. Zunächst ist klar, dass Basiswechsel hinten und vorne nichts ausmachen.
     (Denn ist R invertierbar, so ist auch Lambda^d(R) invertierbar; und ist S
     invertierbar, so ist das Ideal der Einträge von S, (S), das Einsideal.
     Denn wir haben (1) = (S . S^(-1)) <= (S) * (S^(-1)) <= (S).)

  2. Seien x_1,...,x_n Erzeuger mit Präsentationsmatrix A.
     Ist dann A' irgendeine Matrix von gültigen Relationen zwischen den x_i,
     so gibt es eine Matrix T mit AT = A'. Das impliziert:

        (Lambda^(n-i) A') <= (Lambda^(n-i) A).

     Somit spielt zumindest die Wahl der Präsentation bei gegebener
     Erzeugerwahl keine Rolle (dazu dieses Argument zweimal verwenden).

  3. Seien x_1,...,x_n Erzeuger mit Präsentationsmatrix A und seien y_1,...,y_m
     irgendwelche weiteren Elemente. Dann gibt es irgendwelche Relationen
     [ A 0 ; B I ] zwischen den x_i,y_j (hier entsprechen die Zeilen
     Relationen, eigentlich sollte ich transponieren). Also ist

        Fitt_i(M; x_1,...,x_n,y_1,...,y_m) >=
        (Lambda^(n+m-i) [ A 0 ; B I ]) =
        (Lambda^(n+m-i) [ A 0 ; 0 I ]) =
        (Lambda^(n-i) A) =
        Fitt_i(M; x_1,...,x_n).

  4. Seien x_1,...,x_n Erzeuger mit Präsentationsmatrix A und seien y_1,...,y_m
     (andere) Erzeuger mit insgesamter Präsentationsmatrix C. Dann:

        Fitt_i(M; x_1,...,x_n,y_1,...,y_m) =
        (Lambda^(n+m-i) C) <=
        (Lambda^(n+m-i) [ C; B I ]) =
        (Lambda^(n+m-i) [ C' 0; B I ]) =
        (Lambda^(n-i) C') <=   (C' sind Relationen der x_i)
        Fitt_i(M; x_1,...,x_m).

     Zusammen mit 3. ergibt das:

        Fitt_i(M; x_1,...,x_m) = Fitt_i(M; x_1,...,x_n,y_1,...,y_m).

     Das genügt.

  In 3. und 4. verwendet:

      (Lambda^(a+b) [ A 0 ; B I ]) = (Lambda^a A),

  wenn I eine (b x b)-Einheitsmatrix ist.

* Fitt_i(M) <= Fitt_(i+1)(M).

  Außerdem Fitt_b(M) = (Lambda^(b-b) A) = (Lambda^0 A) = (1).
  Und, wenn man so möchte, Fitt_{-1}(M) = (Lambda^(b+1) A) = () = (0).

* Fitt_i(M tensor R') = die Idealerweiterung von Fitt_i(M) in R'.

* Wenn M durch n Erzeuger gegeben werden kann, so ist Fitt_n(M) = (1).
  Klar, denn eine mögliche Präsentationsmatrix hat dann ja nur n Zeilen
  und (Lambda^0) = (1).

  Wenn der Grundring lokal ist, gilt auch die Umkehrung! Denn dann finde ich in
  einer Präsentationsmatrix von M mit m Zeilen einen invertierbaren
  (m-n)-Minor. Den kann man nach oben links bringen, sodass M also durch eine
  Präsentation der Form [ I 0 ; 0 ? ] gegeben ist. Die Restmatrix hat dabei
  nur noch n Zeilen.

* Wenn M frei vom Rang n ist, so ist Fitt_{>= n}(M) = (1) und Fitt_{< n}(M) = (0).
  Klar, denn dann ist eine mögliche Präsentationsmatrix die eindeutig bestimmte
  (n x 0)-Matrix.

  Wenn der Grundring lokal ist, gilt auch hier die Umkehrung! Denn dann gilt

      (?) = (Lambda^1(?)) = (Lambda^(1+m-n) [ I 0 ; 0 ? ])
        = Fitt_{n-1}(M) = (0),  also ? = 0.

  Folglich rk(M) <= n genau dann, wenn Fitt_n(M) = (1).
  Dabei ist rk(M) die Minimalzahl benötigter Erzeuger (in einer
  Vervollständigung der natürlichen Zahlen).

* Es gilt auch (jetzt auf einem Schema oder lokal geringten Raum): Die Menge
  V(Fitt_(b-1)) enthält genau die Punkte, wo M frei vom Rang b ist.

* Fitt_0(M) <= Ann(M): Sei N ein quadratischer Ausschnitt aus der
  Präsentationsmatrix (alle Zeilen, aber vielleicht nicht alle Spalten
  umfassend) und det(N) der zugehörige Minor. Dann ist das Bild von

      det(N) * Id = N * ad(N)

  in M Null.

* Ann(M) <= sqrt(Fitt_0(M)), also sqrt(Ann(M)) = sqrt(Fitt_0(M)).

  Denn sei a aus Ann(M) mit M = cok(A), wobei A n Zeilen habe.
  Dann gibt es eine Matrix U mit a I = A U. Auf der Ebene der n-Minoren erhält
  man daher (a^n) <= (Lambda^n A) = Fitt_0(A).

* Fitt_{k-1}(M) <= Ann(Lambda^k M) und Gleichheit nach Radikalbildung.
  https://www.msri.org/~de/papers/pdfs/1977-003.pdf

* Sei E ein O_X-Modul lokal von endlicher Präsentation.

  Dann gilt: rk_x(E) = rk E_x <= n für alle x aus D(Fitt_n(E)).
  Beser: rk_x(E) = rk E_x <= n genau dann, wenn x aus D(Fitt_n(E)).
  Stimmt das?

  Denn intern gilt: Fitt_n(E) = (1) ==> rk E <= n.

* V(Fitt_i(M)) ist der Ort derjenigen Punkte x, wo M_x nicht durch i
  Elemente erzeugt werden kann.

* Wenn Fitt_{r-1}(M) = 0, dann ist V(Fitt_r(M)) der Ort, wo M_x nicht
  frei vom Rang r ist.

* Sei der Grundring nicht unbedingt lokal. Dann gilt für einen endlich
  präsentierten Modul trotzdem: M = 0 <==> Fitt_0(M) = (1).
  Ganz einfach wegen Fitt_0(M) <= Ann(M).

* In https://www-fourier.ujf-grenoble.fr/sites/ifmaquette.ujf-grenoble.fr/files/bertin_rev.pdf
  scheint behauptet zu werden (Lemma 1.21 und 1.22): Ist Fitt_n(M) = (1), so ist
  Fitt_(n-1)(M/M[Fitt_n(M)]) = (0). Dabei ist M[Fitt_n(M)] die Menge derjenigen
  x aus M, sodass Fitt_n(M) x = 0.

  Diese Behauptung ist aber falsch. Sei M so, dass Fitt_(n-1)(M) = 0. Das ist
  ja durchaus möglich. Dann ist M[Fitt_n(M)] = M und damit der Quotient Null.
  Desser Fitting-Ideale sind (für n >= 0) alle (1).

  Vielleicht habe ich die Behauptung auch missverstanden.

* Sei A^m --> A^n --> M --> 0 exakt. Dann ist M genau dann frei vom Rang n,
  wenn im(A^m --> A^n) = 0. Die Rückrichtung ist klar. Die Hinrichtung folgt,
  weil dann A^n --> M durch eine quadratische surjektive Matrix darstellbar
  ist. Solche sind schon bijektiv (denke an die Determinante).

  Sei n minimal mit der Eigenschaft, dass es eine kurze exakte Sequenz
  A^m --> A^n --> M --> 0 gibt. Dann ist M genau dann endlich frei, wenn
  im(A^m --> A^n) = 0.

* Northcott definiert in seinem Buch zu endlichen freien Auflösungen
  Fitting-Ideale auch für Moduln, die nur endlich erzeugt sind. Diese sind dann
  möglicherweise nicht endlich erzeugt.

Werbung für Fitting-Ideale macht unter anderem:
http://swc.math.arizona.edu/aws/2006/06StillmanNotes.pdf


=== Homogene Polynome

* Homogene Polynome in zwei Variablen sind "genauso gut" wie Polynome
  in einer Variablen. Insbesondere zerfallen sie in Linearfaktoren,
  falls der Grundkörper algebraisch abgeschlossen ist.

* Seien f_1, ..., f_l homogene Polynome (vom selben Grad?).

  Genau dann gilt 1 in (f_1(1,X_2,...,X_n), ...), wenn X_1 in sqrt((f_1,...))
  liegt.


=== Resultante

* Über Ringen mit 1 != 0 und != 0 ==> inv und a|b v b|a gilt:
  Ist eine quadratische Matrix injektiv, so ist ihre Determinante invertierbar.
  Denn man kann die Matrix auf Smithsche Normalform bringen.

* Falls zusätzlich der Ring reduziert ist, folgt: Die Matrix [a b; c d]
  ist injektiv, falls X^n in (aX+bY,cX+dY) und Y^m in (aX+bY,cX+dY).

* Die Sache mit der Resultante geht in etwa so.

  Seien f und g homogene Polynome in X und Y von Graden n bzw. m.
  Gelte X^n in (f,g) und Y^m in (f,g).

  Sei f(X) p(X) + g(X) q(X) = 0, wobei deg(p) <= m-1 und deg(q) <= n-1.
  Wir wollen zeigen, dass alle Koeffizienten von p und q nilpotent sind. Das
  ist eine negneg-stabile Behauptung. Wir dürfen also voraussetzen, dass g in
  Linearfaktoren zerfällt. Jede der Nullstellen ist auch Nullstelle von f(X) p(X).
  Wir dürfen voraussetzen, dass f(x_i) = 0 oder p(x_i) = 0. Im ersten Fall
  haben wir einen Widerspruch.


=== Polynomringe

* Der Polynomring A[X] ist der Ring der natürlichen Trafos U ==> U,
  wobei U : Alg(A) --> Set der Vergissfunktor ist. Dabei wird ein Polynom f
  auf die Trafo (x in R |-> f(x))_R und eine Trafo eta auf eta_{A[X]}(X) geschickt.

* Sei A ein Ring. Sei A[X] ein bézoutscher Ring (endlich erzeugte Ideale
  sind Hauptideale). Dann hat A folgende Eigenschaft: Aus regulär folgt
  invertierbar.

  Denn sei a in A regulär. Da (a,X) ein Hauptideal ist, gibt es Polynome d, f,
  g, h, p mit

      d = f a + g X,
      X = h d,
      a = p d.

  Setzt man für X 0, so erhält man

      d(0) = f(0) a,
      0    = h(0) d(0),
      a    = p(0) d(0).

  Da a regulär ist, ist auch d(0) regulär. Somit ist h(0) = 0.
  Also ist h = X h' für ein h', und aus der Gleichung X = h d folgt
  1 = h' d. Setzt man wieder 0 für X ein, so erhält man 1 = h'(0) d(0).
  Also ist d(0) invertierbar. Damit ist auch a invertierbar.

* Allgemein gilt wohl: Genau dann ist A[X] ein Hauptidealring, wenn
  A ein Produkt von Körpern ist.
  http://math.stackexchange.com/questions/91587/ring-of-polynomials-is-a-principal-ideal-ring-implies-coefficient-ring-is-a-fiel
  http://math.stackexchange.com/questions/361258/in-a-principal-ideal-ring-is-every-nonzero-prime-ideal-maximal

  Die Hinrichtung geht so. Wir zeigen, dass A --> prod_m A/m ein Iso ist.
  Zur Injektivität sei ein a aus A gegeben, welches in allen maximalen Idealen
  liegt. Sei also 1-ab für alle b aus A invertierbar. Wir zeigen, dass a = 0.
  Das können wir halmweise testen. Wir dürfen also annehmen, dass A lokal ist.
  ...???

  Zumindest ist klar: Sei A ein lokaler Ring, sodass A[X] bézoutsch ist.
  Dann ist A ein Körper in dem Sinn, als dass nicht-invertierbare Elemente
  schon Null sind. Denn:

  Sei a in A nicht invertierbar. Da (a,X) ein Hauptideal ist, gibt es Polynome
  d, f, g, h, p mit

      d = f a + g X,
      X = h d,
      a = p d.

  Aus 1 = h_0 d_1 + h_1 d_0 folgt, da A lokal ist, dass h_0 d_1 oder h_1 d_0
  invertierbar ist. Im letzten Fall folgt, dass a invertierbar ist; das kann
  nicht sein. Im ersten Fall folgt, dass d_0 = 0 und somit a = 0.

* Ferner gilt: Genau dann ist A[X] ein bézoutscher *Bereich*, wenn A ein
  Körper ist.

  Die Rückrichtung ist klar (Polynomdivision).
  Bei der Hinrichtung folgt zunächst, dass A ebenfalls ein Integritätsbereich
  ist. Außerdem sind reguläre Elemente invertierbar. Somit ist A ein Körper.

* A[X] ist genau dann ein strikter Bézoutscher Bereich, wenn A regulär ist.
  https://arxiv.org/pdf/1404.4549.pdf, Seite 3.

* Über dem Ring Z[A_0,...]/(A_0^2,...) hat die Potenzreihe f = sum_i A_i X^i
  zwar nilpotente Koeffizienten, sie ist aber selbst nicht nilpotent. Denn
  der Koeffizient von X^(n*(n+1)/2) in f^(n+1) ist

      (n+1)! * A_0 ... A_n,

  also nicht Null. (Von Matthias Schlüter.)

* A[[X]]/(X) ist isomorph zu A, vermöge f |-> f(0).

  Aber A[[X]]/(X-a) ist nicht unbedingt isomorph zu A. Tatsächlich ist
  A[[X]]/(X-a) der Nullring, wenn a invertierbar ist.

* Der Wurzelinhalt eines Polynoms f = sum_i a_i X^i ist c(f) := sqrt((a_i)_i).
  Man kann auch für Teilmengen M von A[X] definieren: c(M) := sqrt(sum_{f in M} c(f)).

  Dann kann man zeigen:
  * c(fg) = c(f) cap c(g).
  * c(f + g) <= sqrt(c(f) + c(g)).
  * c(M) = c((M))  (erzeugtes Ideal).
  * c(sqrt(I)) = c(I).
  * c(I * J) = c(I cap J) = c(I) cap c(J) = c(I) * c(J).

  So wird also ein Rahmenhomo Rad(A[X]) --> Rad(A) bzw. eine stetige Abbildung
  Spec(A) --> Spec(A[X]) definiert. Auf Punkten schickt diese ein Primideal p
  auf p[X].

  Steht auch in Banaschewski, Polynomials and radical ideals,
  http://www.sciencedirect.com/science/article/pii/0022404995001492 (Prop. 2).

* Die nichttriviale Inklusion c(fg) >= c(f) cap c(g) kann man explizit
  und konstruktiv durch Induktion so zeigen. Die rechte Seite ist
  sqrt((a_i b_j)_ij), die linke sqrt((sum a_i b_j)_n).

  Der Erzeuger a_0 b_0 der rechten Seite liegt auch in der linken.

  Nun betrachten wir a_i b_j. Dann gilt:

      (a_i b_j)^2 = a_i b_j (sum_{k+l=n} a_k b_l) -
          sum_{k+l=n, k<i oder l<j} a_i b_j a_k b_l.

  Wenn k < i ist, dann liegt a_k b_j nach Induktionsvoraussetzung in der linken
  Seite. Analog liegt a_i b_l in der linken Seite, falls l < j ist. Also
  liegen alle Summanden in der linken Seite.

* Die Sache mit dem Wurzelinhalt zeigt, dass in lokalen Ringen gilt:

      Genau dann gibt es ein n, sodass sum_{i+j=n} a_i b_j invertierbar ist,
      wenn es ein i gibt, sodass a_i, und wenn es ein j gibt, sodass b_j
      invertierbar ist.

  Die Hinrichtung ist trivial, aber die Rückrichtung nicht.

  Die Aussage stimmt auch in N-graduierten Ringen, welche nur graduiert-lokal
  sind (ist eine Summe homogener Elemente gleichen Grads invertierbar, so schon
  ein Summand), wenn die a_i und b_j jeweils homogen von dem Grad sind, wie ihr
  Index angibt. Das zeigt obige explizite Rechnung, die keinen Unsinn mit den
  Graden treibt. Vielleicht folgt das auch schon abstrakt direkt aus der
  Aussage statt dem Beweis.

* http://math.stackexchange.com/a/53229/61604:

      I cap J = (t I + (1-t) J) cap k[x_1,...,x_n]

  für Ideale I und J von k[x_1,...,x_n]. (Der Schnitt findet in
  k[x_1,...,x_n,t] statt.)

  Allgemeiner gilt das für Ideale I und J eines Rings A, wobei der Schnitt dann
  in A[t] stattfindet.

* Gröbner-Basen:
  * http://people.math.gatech.edu/~aleykin3/math4803spr13/BOOK/chapter3.pdf
  * Hervé Perdry. Strongly Noetherian rings and constructive ideal theory.
  * http://people.csail.mit.edu/madhu/ST12/scribe/lect15.pdf

* Im Allgemeinen gilt bekanntlich nicht I cap (J + K) = (I cap J) + (I cap K).
  Ein Beispiel lautet:

      I = (x), J = (x+y), K = (y) in Q[X,Y].

  Dann ist die linke Seite gleich (x) und die rechte gleich (x) * (x,y).

* Hinreichend für a cap (b + c) = (a cap b) + (a cap c) ist b <= a oder c <= a.
  (Das heißt auch "modular law".)

* Sei phi : A --> B ein surjektiver Ringhomo. Sei p ein Primideal von A.
  Wenn ker(phi) <= p, dann ist phi[p] ein Primideal von B.

* Man könnte denken, dass zum Beispiel in K[X,Y] gilt:

      (f_i)_i cap (g_j)_j = (kgV(f_i,g_j))_ij.

  Aber das ist falsch, wie das Beispiel

      (x+y) = (x,y) cap (x+y) != (x,y) * (x+y) = (kgV(x,x+y), kgV(y,x+y))

  demonstriert.

* Eisenstein funktioniert über beliebigen Integritätsbereichen.
  Aber man muss aufpassen, was dann Primelemente sind.
  https://en.wikipedia.org/wiki/Eisenstein%27s_criterion


=== Graduierte Ringe

* Ein N-graduierter Ring, welche eine homogene Einheit u vom Grad 1 enthält,
  ist nicht viel spannender als sein Grad-0-Anteil. Denn es gilt:

  * S_n = u^n S_0.

  * xy = u^{i+j} (u^{-i} x) (u^{-1} y), wenn x in S_i und y in S_j liegt.
    Die hintere Multiplikation findet dabei in S_0 statt.

  * 0 --> (u-1) --> S --> S_0 --> 0 ist eine exakte Sequenz.
                    x |-> u^{-i} x, falls x homogen vom Grad i

* Es ist S_p, also die Lokalisierung eines N-graduierten Rings S an
  den homogenen Elementen aus S \ p (wobei p ein homogenes Primideal ist, in
  dem ein Element aus S_1 nicht enthalten ist), ein solcher Ring. Deswegen ist
  es okay, nur S_(p) zu betrachten, den Grad-0-Anteil.

* Seien M und N graduierte S-Moduln. Sei F ein multiplikatives System von S
  bestehend nur aus homogenen Elementen. Dann gibt es eine kanonische lineare
  Abbildung

      M[F^(-1)]_0 tensor_{S[F^(-1)]_0} N[F^(-1)]_0 --> (M tensor_S N)[F^(-1)]_0
      x/s tensor y/t |--> (xy)/(st).

  Diese ist im Allgemeinen jedoch kein Iso.

  Aber schon, wenn F ein Element u vom Grad 1 enthält: Dann ist ein Urbild für
  (x tensor y) / s nämlich ((u^m x) / s) tensor (y / u^m), wenn y Grad m hat.
  Eine andere Wahl von u führt übrigens zum gleichen Tensor.

* Was bitte ist die universelle Eigenschaft des Grad-0-Teils der Lokalisierung?
  Es muss doch besser gehen als wie von mir spekuliert: http://mathoverflow.net/questions/142234/is-there-a-universal-property-for-graded-localization/249110#249110

* Sei f : R --> S ein Morphismus graduierter Ringe. Dann ist f genau dann
  surjektiv, wenn alle f_n surjektiv sind.


=== Homogene Ideale

* Ein Ideal I in einem graduierten Ring S ist genau dann homogen, wenn für
  alle Elemente a = sum_i a_i (Zerlegung in homogene Komponenten) von S gilt:

      Liegt a in I, so liegen schon alle a_i in I.

  Das ist genau dann der Fall, wenn es ein Erzeugendensystem für I gibt,
  welches nur aus homogenen Elementen besteht.

* Der Idealquotient (a : b) ist homogen, falls a und b es sind.

* Das Wurzelideal eines homogenen Ideals ist homogen, falls wir etwa über einen
  N-graduierten Ring sprechen. Der Beweis geht über Induktion über den höchsten
  vorkommenden Grad:

      Sei f = sum_{i=0}^n f_i in sqrt(a), also f^m in a für ein m >= 0. Wir
      wollen zeigen, dass alle f_i in sqrt(a) liegen. Der größte (potenziell)
      vorkommende Grad in f^m ist nm mit Koeffizient f_n^m. Da a homogen ist,
      liegt also f_n^m in a. Somit liegt f_n in sqrt(a). Nun machen wir weiter
      mit f - f_n.

* Es gibt zwei Möglichkeiten, aus einem beliebigen Ideal ein homogenes zu
  machen.

      I^h := { f | forall i. exists g in I. f_i = g_i }
           = (g_i | g in I, i >= 0) >= I

      I^k := { f | f_i in I für alle i } <= I
           = oplus_{d >= 0} (I cap S_d)

  Es gilt: (__)^h -| Homogenität vergessen -| (__)^k.

  Die erste Adjunktion sagt aus: Um I^h <= J zu zeigen, wobei J homogen ist,
  genügt es, I <= J nachzuweisen. Die zweite sagt aus: Um J <= I^k zu zeigen,
  wobei J homogen ist, genügt es, J <= I nachzuweisen.

  I^h ist der Schnitt über alle homogenen Ideale, welche I umfassen.
  I^k ist die Summe über alle homogenen Ideale, welche in I enthalten sind.

* Ich sehe nicht, dass (__)^h und (__)^k Radikalität erhalten.

* Es gilt: a^h cap b^h = sqrt((a * b)^h). Dabei ist ">=" trivial (nur
  Monotonie).

  Für die nichttriviale Richtung benötigt man folgendes Lemma:

      Ist f in a und g in b, so liegt f_i g_j in sqrt((a * b)^h).

  Das zeigt man durch Induktion über n := i + j, genau wie beim Radikalinhalt.


=== Projektoren (Idempotente)

* Sei phi : V --> V ein Projektor (ein idempotenter Morphismus) in einer
  abelschen Kategorie. Dann ist V = ker phi oplus im phi.
  Also cok phi = ker phi.

  Außerdem besitzt der Monomorphismus im(phi) --> V einen Koschnitt,
  nämlich V --phi--> im(phi).

  Das impliziert zum Beispiel, dass für einen Basiswechsel R --> S und eine
  idempotente Matrix P über R gilt: im(P) tensor_R S = im(P tensor_R S).

* Nicht alle endlich präsentierbaren abelschen Gruppen können als Kokern
  eines Projektors geschrieben werden. Denn Kerne von Z-Matrizen (also Kokerne
  von Projektoren) sind ja stets frei. 

* In Ab_fp kann jedes Objekt als Kokern einer injektiven Matrix zwischen
  freien Moduln dargestellt werden. Aber nicht als Kern einer surjektiven.
  Wenn man freie Moduln kategoriell und selbstdual charakterisieren kann, zeigt
  das, dass Ab_fp^op nicht zu Ab_fp äquivalent ist: In Ap_fp kann nicht jedes
  Objekt als Kern einer surjektiven Abbildung zwischen freien Moduln
  geschrieben werden, in Ab_fp^op dagegen schon.

* Auf jeden Fall gibt es folgendes Unterscheidungsmerkmal: In Ab_fp gibt
  es ein Objekt X, sodass Hom(X, __) : Ab --> Set treu ist. (Nämlich X = ZZ.)
  In Ab_fp^op gibt es das aber nicht.

* Sei e ein idempotentes Element in einem Ring. Dann gilt Ann(e) = (1-e).
  Dabei ist ">=" klar. Die andere Richtung gilt sogar ganz ohne
  Voraussetzungen: Wenn xe = 0, dann x = x (e + (1-e)) = x (1-e).


=== Vektorräume ohne kanonische Basis

* Kerne von linearen Abbildungen

* Kern von exp : O_X --> O_X^*.


=== Cayley--Hamilton

* Beweis über Zariski-Dichtheit:
  http://www.matheplanet.com/matheplanet/nuke/html/article.php?sid=1200


=== Ideale

* a cap b = a * b, falls a + b = (1).

* a cap b = sqrt(a * b), falls a und b Radikalideale sind.
  ">=" ist klar. "<=" auch.

* (a + b)^n = sum_{i+j=n} a^i b^j.

* Stets gilt sqrt(0 : a) <= sqrt(0) : a. Die andere Richtung gilt im
  Allgemeinen nicht.

* Die Menge der Nullteiler eines Rings ist stets die Vereinigung all
  derjenigen Primideale, die nur aus Nullteilern bestehen. (B2, A5)

* Minimale Primideale bestehen stets nur aus Nullteilern.

  Denn: Sei p ein minimales Primideal. Dann besitzt A_p nur ein einziges
  Primideal. Ist also x in p, so ist x in A_p nicht invertierbar und somit
  nilpotent. Also gibt es ein u nicht aus p und ein n >= 1 mit x^n u = 0.
  Wählt man n minimal, so sieht man, dass x ein Nullteiler ist.

  In reduzierten Ringen gilt auch die Umkehrung, das heißt: Jeder Nullteiler
  liegt in einem minimalen Primideal.

  Denn: Sei x ein Nullteiler. Gelte also x u = 0 mit u != 0.
  Dann ist u nicht nilpotent. Also gibt es ein minimales Primideal p
  mit u nicht in p. Somit x in p.

  Die Umkehrung gilt aber auch in manchen nicht-reduzierten Ringen.
  Zum Beispiel in k[eps]/(eps^2): Da sind die Nullteiler gerade alle Vielfachen
  von eps. Es gibt nur ein Primideal, nämlich (eps). Also gilt Gleichheit.

  Allgemein gilt: Die Vereinigung aller minimalen Primideale ist die Menge
  derjenigen Elemente x, sodass ein nicht-nilpotentes u derart existiert, dass
  xu nilpotent ist.

* Jeder reduzierte Ring bettet in ein Produkt von Körpern ein:

      A ----> prod_{minimale Primideale p} Quot(A/p).

  Hier geht ein, dass der Schnitt über alle minimalen Primideale gleich dem
  Nilradikal und daher gleich dem Nullideal ist.

  Übrigens ist Quot(A/p) = A_p = A_p / pA_p = k(p).
  (Das gilt allgemein für minimale Primideale von reduzierten Ringen.)

  Siehe auch Tag 02LV im Stacks Project.

* Ist m ein maximales Ideal, so gilt: Quot(A/m) = A/m = A_m / mA_m = k(m).

* In einem reduzierten Hauptidealring gilt: Jedes Primideal, das nicht
  minimal ist, ist maximal.

  Denn: Sei p = (x) ein nicht-minimales Primideal. Dann enthält p ein reguläres
  Element. Denn angenommen p würde nur Nullteiler enthalten. Dann ist p
  die Vereinigung aller minimalen Primideale. Das Element x liegt also in einem
  bestimmten minimalen Primideal q. Also p <= q. Da q minimal ist, ist p = q.
  Das ist ein Widerspruch zur Nicht-Minimalität von p.

  Somit enthält p ein reguläres Element tx. Damit ist auch x selbst regulär.

  Sei nun ein Ideal a = (y) mit p <= a gegeben. Dann x = sy für ein Element s.
  Also s in p oder y in p. Im zweiten Fall folgt a <= p, also fertig.

  im ersten Fall gibt es u mit s = ux. Also x = sy = uxy. Da x regulär ist,
  folgt 1 = uy. Damit ist a das Einsideal.

* In einem beliebigen Hauptidealring, der nicht unbedingt reduziert ist,
  gilt ebenfalls: Jedes Primideal, das nicht minimal ist, ist maximal.

* Hom_R(R/I, R/I) = R/I als R- und als R/I-Moduln.

* Eine allgemeine Version des chinesischen Restsatzes: Seien I und J
  Ideale. Dann haben wir eine kurze exakte Sequenz

      0 --> A/(I cap J) --> A/I oplus A/J --> A/(I + J) --> 0.
                      f |-> (f,f)   (f,g) |-> f-g

  Injektivität vorne ist klar. Surjektivität hinten auch. Exaktheit in der
  Mitte so: Seien (f,g) mit f - g in I + J, d.h. f - g = u + v mit u in I und v in J.
  Dann ist g + v = g + u + v = g + (f - g) = f mod I und g + v = g mod J.

* Beispiel, wo "naive Isomorphie-Regeln" das falsche Ergebnis liefern:

      "Z[sqrt(5)]/(sqrt(5)-1) = Z[1] = Z" ist Quatsch. Richtig:

      Z[sqrt(5)]/(sqrt(5)-1) = Z[X]/(X^2-5, X-1) = Z[X]/(1-5, X-1) =
        (Z/(4))[X]/(X-1) = Z/(4).

* Sei a + b endlich erzeugt. Dann gibt es endlich erzeugte Ideale a_0 <= a
  und b_0 <= b mit a + b = a_0 + b_0.

  Denn: Die Erzeuger von a + b können wir in der Form u_i + v_i mit u_i
  in a und v_i in b schreiben. Dann setzen wir a_0 := (u_i)_i <= a und
  b_0 := (v_i)_i <= b.

  Im Fall, dass b selbst schon endlich erzeugt ist, können wir b_0 := b
  wählen. Denn a_0 + b_0 = a_0 + b.

* Sei a + (x) = a_0 + (x). Dann gilt

      a = a_0 + (x) * (a : x_0).

* Sei sqrt(a) endlich erzeugt. Dann sqrt(a)^n <= a für ein n.


=== Dreiecksmatrizen

* Eine quadratische Matrix A lässt sich genau dann auf obere Dreiecksform
  bringen, wenn es eine A-invariante Flagge von k^n gibt.

* Hinreichend und notwendig dafür ist, dass das charakteristische Polynom
  von A über k in Linearfaktoren zerfällt. Die Notwendigkeit ist klar. Für die
  andere Richtung startet man mit einem Eigenvektor v, lässt A auf den
  Quotienten k^n/span(v) absteigen und macht weiter.


=== Smithsche Normalform

* Die SNF existiert über (konstruktiv) über allen Ringen, in denen endlich
  erzeugte Ideale Hauptideale sind und für Hauptideale die aufsteigende
  Kettenbedingung erfüllt ist. Und die außerdem (schwache/starke?)
  Integritätsbereiche sind.

* Die SNF existiert aber auch über Ringen, in denen von je zwei Elementen eines
  das andere teilt. Solche müssen nicht noethersch sein.

* Über gerichteten Vereinigungen von Ringen, über denen jeweils die SNF
  existiert, existiert die SNF ebenfalls. Solche Vereinigungen können auch
  nicht noethersch sein, siehe etwa
  http://mathoverflow.net/questions/31275/does-smith-normal-form-imply-pid.

* Ringe, über denen die SNF stets existiert, heißen elementary divisor rings.
  Eine vollständige Charakterisierung gibt Theorem 6 in
  https://www.math.hmc.edu/~henriksen/publications/1956_Gillman_Henriksen_Some_remarks_about_elementary_divisor_rings.pdf.

* Es gibt schicke nichtkonstruktive Beweise der Klassifikation endlich
  präsentierter abelscher Gruppen.
  http://mathoverflow.net/questions/12009/is-there-a-slick-proof-of-the-classification-of-finitely-generated-abelian-group

* Sei A eine (n x n)-Matrix über einem Körper. In erster Näherung legt das
  Spektrum von A -- die Menge der Eigenwerte -- A bis auf Konjugation fest.
  Aber das stimmt natürlich nicht wirklich, da man die Information über die
  Feinstruktur der Jordan-/Weierstraßform verliert.

  Allerdings können wir A bis auf Konjugation aus dem k[x]-Modul k^n_phi
  zurückgewinnen. Dieser hat Träger genau auf ... dem Spektrum! Er ist also
  eine Art verfeinertes Spektrum. Richtig interpretiert, stimmt das sogar dann,
  falls das charakteristische Polynom von A über k nicht in Linearfaktoren
  zerfällt. (Es gilt: supp k^n_phi = { (f) | f irreduzibler Faktor im
  charakteristischen Polynom oder Minimalpolynom von f }.)

  Definiere den schematheoretischen Träger eines Moduls M als V(Ann M),
  wobei Ann M = { s : A | sM = 0 }. Dann ist der schematheoretische Träger von
  k^n_phi gleich V(mu_phi), wobei mu_phi das Minimalpolynom ist. Das folgt
  sofort mit der Smithschen Normalform, denn

      k^n_phi = oplus_i k[X]/(f_i)  mit f_1 | f_2 | ...,

  also

      Ann(k^n_phi) = bigcap_i Ann(k[X]/(f_i)) = bigcap_i (f_i) = (f_r) = (mu_phi),

  somit V(Ann(k^n_phi)) = V(mu_phi) schematheoretisch.

* Die charakteristischen Polynome von AB und BA stimmen miteinander überein,
  wenn A und B quadratische Matrizen gleicher Größe sind. Im Fall, dass eine
  der beiden Matrizen invertierbar ist, ist das klar (Ähnlichkeit), und der
  allgemeine Fall folgt mit abstraktem Nonsens (Polynomidentität und so -- gehe
  von Z[a_11,...,a_nn,b_11,...,b_nn] zu Q(a_11,...,b_nn) über).
  https://mymathadventure.wordpress.com/2009/05/17/characteristic-polynomials-commute/

* Die Isomorphietypen von V_AB und V_BA in Coh(k[X])/X-Torsion = Coh(k[X,X^(-1)])
  stimmen miteinander überein (vermöge Iso [v] |-> [Av] und [w] |-> [1/X Bw]).
  Dabei ist unerheblich, ob A und B quadratisch und von der gleichen Größe
  sind. Sie müssen nur in beide Richtungen komponierbar sein.

  Als Korollar sieht man: Die Weierstraßnormalform (ohne Blöcke zu k[X]/(X^n))
  stimmen überein.

* Wie man Homologie von Komplexen berechnen kann:
  https://jeremykun.com/2013/04/10/computing-homology/


=== Eigenwerte und Eigenvektoren

* Sei A eine quadratische Matrix. Zerfalle ihr charakteristisches
  Polynom f(X) in Linearfaktoren (X - x_i). Gelte zudem für alle i, j:
  x_i = x_j oder x_i - x_j ist invertierbar.

  Dann sollte es möglich sein, eine Bézoutdarstellung

      a(X) (X - lambda)^m + b(X) (X - ...) ... (X - ...) = 1

  zu finden. Dann kann man nachrechnen, dass

      P := (zweiter Summand)(A)
      Q := (erster Summand)(A)

  komplementäre Projektoren sind, denn P + Q = I und P Q = 0.
  Außerdem folgt:

      im(P) <= ker((A - lambda)^m) <= ker(Q) = im(P),

  also im(P) = ker((A - lambda)^m).

  Ist nun der Grundring lokal, so ist im(P) endlich frei.
  Der Rang kann nicht null sein, sonst wäre (A - lambda)^m injektiv, somit wäre
  auch (A - lambda) injektiv, somit wäre det(A - lambda) regulär.
  Aber det(A - lambda) = \pm f(lambda) = 0. Da 1 != 0, ist das ein Widerspruch.

  http://math.mit.edu/~dav/generalized.pdf


=== Noethersche Ringe

* Polynomringe und Quotienten noetherscher Ringe sind noethersch.
  (klassisch, konstruktiv gut formulieren)

* Also sind alle endlich erzeugten Ringe (Ringe der Form Z[x_1,...,x_n],
  wobei die x_i Ringelemente (und nicht formale Variablen) sind) noethersch.

* Jeder Ring ist gerichteter Kolimes seiner endlich erzeugten Unterringe.
  Also ist jeder Ring gerichteter Kolimes noetherscher Ringe.

* Was sind die kompakten Objekte in der Kategorie der Ringe?


=== Grad des Nullpolynoms

Der Grad des Nullpolynoms sollte -infty (und nicht +infty) sein. Denn sonst stimmt die Regel

    deg(f + g) <= max { deg(f), deg(g) }

nicht: Bedenke 0 = f + (-f). Mit dieser Konvention (aber auch mit +infty)
stimmt auch die Regel

    deg(f * g) <= deg(f) + deg(g).

Außerdem gilt mit dieser Konvention folgende Regel für alle n aus Z:
Ist deg(f) <= n, so lässt sich f in der Form f = sum_{i=0}^n a_i X^i schreiben.


=== Endlichkeitseigenschaften von Moduln

* Sei pi : A^n --> M eine zerfallende surjektive lineare Abbildung.
  Dann ist M ein direkter Summand von pi, ein Iso ist gegeben durch

       A^n  ~~ M + ker pi
         x |-> (pi(x), x - s pi(x))
    s(a)+b <-| (a,b),

  und somit ist ker pi endlich erzeugt. Die Abbildung A^n --> ker pi, x |-> x -
  s(pi(x)) ist (wohldefiniert und) surjektiv.

* Sei phi : M --> A^n eine surjektive lineare Abbildung,
  wobei M endlich erzeugt ist. Dann ist der Kern von phi
  a) ein direkter Summand von M und
  b) somit selbst endlich erzeugt.

  Beweis: Urbilder u_i |-> e_i wählen,
  dann M = ker phi \oplus span(u_i).

  Beweis: Habe eine surjektive lineare Abbildung p : A^m --> M.
  Dann ist (nach dem folgenden) der Kern von A^m --> A^n sogar lokal frei,
  somit insbesondere lokal endlich erzeugt und somit insbesondere tatsächlich
  endlich erzeugt. Das Bild dieses Kerns unter p ist genau ker phi.

* Sei phi : A^m --> A^n eine surjektive lineare Abbildung und
  sei A ein lokaler Ring. Dann ist der Kern von phi frei vom Rang m - n.

  Beweis: Durch Basistrafo kann man die zu phi gehörige Matrix auf die Form
  (Einheitsmatrix | Nullmatrix) bringen.

* Sei phi : A^n --> A^n eine surjektive lineare Abbildung. Dann ist
  phi auch injektiv. Denn sie ist nach dem vorherigen Punkt halmweise injektiv!
  Alternativ: Finde Rechtsinverses. Produktformel für die Determinante sagt,
  dass die Determinante von phi invertierbar ist. Daher ist phi invertierbar.

* Sei phi : M --> M ein surjektiver Endomorphismus eines endlich erzeugten
  A-Moduls M. Dann ist phi ein Isomorphismus.

  Siehe http://math.uga.edu/~pete/integral.pdf, Theorem 3.43: Fasse M als
  A[t]-Modul auf. Sei I das Ideal (t) in A[t]. Dann gilt IM = M. Also gibt es
  nach Nakayama ein Element f(t) aus A[t] mit f(t) = 1 modulo I und f(t) M = 0.
  Somit gibt es ein Polyno g(t)mit 1 - f(t) = g(t) t. Sei nun x mit phi(x) = 0.
  Dann folgt x = (1 - f(t)) x = g(t) t x = g(t) phi(x) = 0.

  Steht auch in http://math.stackexchange.com/a/239419/61604.

* Sind in einer kurzen exakten Sequenz die äußeren beiden Moduln frei von
  endlichem Rang, so auch der mittlere.

  Falls der Grundring lokal ist, folgt aus der Freiheit der rechten beiden
  Moduln die Freiheit des linken.

  Aber die Freiheit des Kokerns folgt im Allgemeinen nie.
  Das sieht man etwa schon an Z_(2) --> Z_(2), z |--> 2z.

* Ein Hauptideal (f) von A ist genau dann frei vom Rang 1, wenn f regulär ist.

* Genau dann ist A/(f) über A endlich frei, wenn f Null oder invertierbar ist.

  Denn falls A/(f) frei vom Rang 0 ist, so ist f invertierbar.

  Falls A/(f) frei von einem Rang >= 1 ist, so gibt es eine A-lineare
  Injektion A --> A/(f). Unter der wird f = f * 1 auf f * ??, also auf Null,
  abgebildet, womit f selbst schon Null ist.

  Gilt sogar, wenn man von A/(f) nur weiß, dass es über A frei ist.
  (Damit ist es ja dann frei über eine kuratowskiendlichen Menge.)

* Beachte: Familien aus mehr als einem Element in einem nichttrivialen Ring
  können niemals linear unabhängig sein. Leicht: Seien x, y linear unabhängig.
  Dann gilt yx - xy = 0, also y = -x = 0. Dann 1x = 0, also 1 = 0.

* Es stimmt *nicht*, dass ein Modul, der halmweise endlich erzeugt ist, schon
  selbst endlich erzeugt ist. Ein Gegenbeispiel ist über A = Z der Modul
  oplus_{p prim} F_p^p, dessen Halme (F_p^p bzw. 0) alle endlich erzeugt sind.

  Etwas kurioserweise impliziert ein konstruktiver Beweis von "M[F^(-1)] ist
  endlich erzeugt" eben schon, dass M endlich erzeugt ist.


=== Kohärente Moduln

* Sind in einer kurzen exakten Sequenz zwei der drei Moduln kohärent,
  so auch der dritte.

* Endlich erzeugte Untermoduln kohärenter Moduln sind kohärent.

* M e.p., N kohärent ==> Hom(M,N) kohärent.

* Ein Ring A ist genau dann kohärent als Modul über sich selbst,
  wenn endlich präsentierte Moduln schon kohärent sind.

* In diesem Fall ist die Unterkategorie der kohärenten Moduln
  die kleinste abelsche Unterkategorie aller Moduln, welche
  die freien Moduln endlichen Rangs (und beliebige Abbildungen zwischen ihnen)
  umfasst.

* Jeder endlich präsentierte A-Modul ist Kokern eines Monomorphismus
  (nutze Epi-/Mono-Faktorisierung).

* Jeder endlich präsentierte Z-Modul ist Kokern einer injektiven Matrix.
  Genauso mit Q[X] statt Z. Nutze Smithsche Normalform.

* Bilder von Z-Matrizen sind stets Z-frei. (Nutze Smithsche Normalform.)
  Als Konsequenz sind endlich erzeugte Untermoduln von Z^n frei.

  Für Z/(4) statt Z ist das falsch, wie die Matrix (2) oder der Untermodul
  2 Z/(4) von Z/(4) zeigt.

  In klassischer Logik ist freilich jeder Untermodul von Z^n endlich erzeugt,
  da Z und somit Z^n noethersch sind.

* Ein Lemma zum Vergleich von Präsentationen. Seien Präsentationen

      0 --> P_1 --> P_0 --> M --> 0
      0 --> Q_1 --> Q_0 --> M --> 0

  gegeben. Sei P_0 projektiv. Dann können wir ein Diagramm der Form

                    i         p
      0 ----> P_1 ----> P_0 ----> M ----> 0
               |         |        |
               | beta    | alpha  | id
               v         v        v
      0 ----> Q_1 ----> Q_0 ----> M ----> 0
                    j        q

  bauen. Dann gibt es eine kurze exakte Sequenz der Form

      0 ----> P_1 ----> P_0 oplus Q_1 ----> Q_0 ----> 0.
                x |---> (i(x),beta(x))
                                (x,y) |---> alpha(x)-j(y)

  Bei der Exaktheit an der mittleren Stelle geht die Monomorphie von j ein.
  Die Monomorphie von i geht für die Exaktheit vorne ein.
  Sonst geht Monomorphie nirgendwo ein.

* Umkehrung: Sei ein Diagramm

                    i
              P_1 ----> P_0
               |         |
          beta |         | alpha
               v         v
              Q_1 ----> Q_0
                    j

  gegeben. Sei ferner die Sequenz

              P_1 ----> P_0 oplus Q_1 ----> Q_0 ----> 0.
                x |---> (i(x),beta(x))
                                (x,y) |---> alpha(x)-j(y)

  exakt. Dann sind die Kokerne von i und von j zueinander isomorph.
  Dabei müssen i und j nicht unbedingt Monos sein.

  Ein expliziter Iso sieht so aus:

      cok(i) ---> cok(j)
         [x] |--> [alpha(x)]

  Er ist wohldefiniert wegen der Kommutativität des Diagramms,
  ist surjektiv wegen der Exaktheit bei Q_0 und ist injektiv wegen der
  Exaktheit an der mittleren Stelle.

* Einen Kokern eines Morphismus der Form

      cok(P' --> P) ----> cok(Q' --> Q)

  kann man umschreiben als Kokern eines Morphismus der Form

      P oplus Q' --> Q,

  wenn P projektiv ist. Und zwar so: Zunächst ändert sich der Kokern nicht,
  wenn man den Kokern von

      P ----> cok(Q' --> Q)

  betrachtet, denn P --> cok(P' --> P) ist ein Epi. Da P projektiv ist,
  liftet der Morphismus P ----> cok(Q' --> Q) zu einem Morphismus P --> Q.

  Dann kann man explizit einen Iso der betreffenden Kokerne angeben.

* Ein Beispiel für einen Ring, über dem nur der Nullmodul kohärent ist:
  k[X_1,...]/(X_i X_j)_ij.
  http://mathoverflow.net/questions/159836/coherent-modules/159841#159841

* Z x Z = Z[X,Y]/(XY, 1 - X - Y) = Z[T]/(T (1-T)).

  Allgemeiner: A[X]/(f) x A[Y]/(g) =
      A[X,Y,T]/(T(1-T), TX, (1-T)f, (1-T)Y, Tg).

  Genauso für noch allgemeinere Produkte endlich präsentierter A-Algebren.

* Tag 00F4: Sei A --> R --> S. Ist A --> S von endlicher Präsentation
  und ist A --> R von endlichem Typ, so ist R --> S von endlicher Präsentation.

* Sei (x_1,...,x_n) ein Erzeugendensystem für einen Modul M mit
  Präsentationsmatrix P. Sei (y_1,...,y_m) ein weiteres Erzeugendensystem.
  [ Dass P Präsentationsmatrix ist, bedeutet: P^T x = 0 und [v^T x = 0 ==> v in im(P)]. ]

  Dann gibt es eine (n x m)-Matrix B mit By = x. (Diese Bedingung stellt auch
  schon sicher, dass (y_1,...,y_m) ein Erzeugendensystem ist.) Analog gibt es
  eine (m x n)-Matrix C mit Cx = y.

  Eine Präsentationsmatrix für (y_1,...,y_m) ist dann

        Q := (B^T P | 1 - B^T C^T).

  Denn: Q^T y = (P^T B y, y - CBy) = (0, 0), und ist w mit w^T y = 0 beliebig,
  so gilt:

      0 = w^T y = w^T C x = (C^T w)^T x = 0,
          also C^T w = P u für ein u,
          somit w = (1 - B^T C^T) w + B^T P u.


=== Endlichkeitseigenschaften von Algebren

* Sei eine R-Algebra S als R-Modul endlich erzeugt.
  Dann ist S auch als R-Algebra endlich erzeugt. (Klar. Kann dieselben Erzeuger
  nehmen.)

* Sei eine R-Algebra S als R-Modul frei von endlichem Rang.
  Dann ist S auch als R-Algebra von endlicher Präsentation.

  Sei dazu x_1, ..., x_n eine Basis von S über R.
  Schreibe

      x_i x_j = sum_k a^ij_k x_k,
      1       = sum_k b_k x_k.

  Dann R[X_1,...,X_n]/(X_i X_j - sum a^ij_k X_k, 1 - sum b_k X_k)
  kanonisch isomorph zu S.

* Sei eine R-Algebra S als R-Algebra endlich erzeugt und
  als R-Modul frei (aber nicht unbedingt endlich frei).
  Existiere sogar ein ???
  Dann ist S als R-Algebra von endlicher Präsentation.

  Sei (x_l)_l eine R-Modul-Basis und (a_i)_i ein endliches Erzeugendensystem
  als R-Algebra. Schreibe

      a_i     = sum_l gamma^i_l x_l,
      a_i a_j = sum_l lambda^ij_l x_l,
      1       = sum_l mu_l x_l.

  Dann ist R[A_i, X_l sodass x_l vorkommt]/(...) kanonisch isomorph zu S.

* Sei eine A-Algebra B durch (x_1,...,x_n) erzeugt mit Relationenideal
  (f_1,...,f_l). Sei B auch durch (y_1,...,y_m) erzeugt.

  Dann gibt es Polygnome g_j in A[X_1,...,X_n] mit g_j(vec x) = y_j.
  Umgekehrt gibt es Polynome h_i in A[Y_1,...,Y_m] mit h_i(vec y) = x_i.

  Das Relationenideal für das EZS (y_1,...,y_m) ist dann

      (f_k(h_*(vec Y)), Y_j - g_j(h_*(vec Y))).


=== Endlichkeitseigenschaften von Körpern

* Sei K ein Körper und L = K(x) ein Oberkörper, sodass für ein n
  die Familie 1, x, x^2, ..., x^n ein EZS ist. Dann kann man konstruktiv nicht
  zeigen, dass L als K-VR frei ist. Aber schon, wenn K faktoriell ist!

* Was, wenn man nur irgendein EZS kennt?


=== Injektivität und Surjektivität

Sei M eine quadratische Matrix über einem Ring.

* Wenn M als Abbildung surjektiv ist, ist sie auch injektiv.
  Denn kann ein Rechtsinverses konstruieren; dann folgt aus der
  Multiplikativität der Determinante, dass det(M) invertierbar ist; und daher
  kann man das Inverse von M explizit angeben.

  Der (1x1)-Fall lautet: Invertierbare Ringelemente sind regulär.
  (Denn Surjektivität von A --> A, Multiplikation mit x, ist gleichbedeutend
  mit Invertierbarkeit von x.)

* Die Umkehrung gilt nicht, auch nicht über lokalen Ringen.

  Betrachte etwa den lokalen Ring Z_(2) und die (1x1)-Matrix (2).
  Da Multiplikation mit 2 injektiv ist, ist diese Matrix als Abbildung
  injektiv. Aber Multiplikation mit 2 ist nicht invertierbar.

  Das passt auch dazu, das Liu sonst seine Übungsaufgabe 5.1.13 stärker
  formuliert hätte.

* Es gilt aber (http://www2.math.uu.se/~palmgren/symposium_constructivity_computability/Coquand.pdf, Folie 22):

  Eine (n x m)-Matrix A mit n <= m ist genau dann injektiv, wenn Delta_n(A)
  (wohl das Ideal ihrer n-Minoren) regulär ist.

  Insbesondere: Eine quadratische Matrix ist genau dann injektiv, wenn ihre
  Determinante regulär ist.

  "<==": Sei Ax = 0. Dann auch ad(A) A x = 0, also det(A) x = 0, also x = 0.

  "==>": Sei det(A) a = 0. Dann auch det(A) [a,...,a] = 0. Damit ad(A) A [a,...,a] = 0.
  Und jetzt? Hilft (1) >= (Lambda^1 A) >= ... >= (Lambda^n A) >= (0)?

  Schick geht es so: Die Matrix A ist genau dann injektiv, wenn ihre Spalten
  (u_i)_i linear unabhängig sind. Das ist genau dann der Fall [*], wenn in
  Lambda^n(A) aus a * (u_1 wedge ... wedge u_n) = 0 schon a = 0 folgt.
  Da Lambda^n(A) von e_1 wedge ... wedge e_n frei erzeugt wird, ist das
  äquivalent zur Regularität von det(A).

  Zu [*], "<==": Sei sum_i a_i u_i = 0. Dann gilt:

      0 = u_1 wedge ... wedge sum_i a_i u_i wedge ... wedge u_n,

  also a_i (u_1 wedge ... wedge u_n) = 0. Also a_i = 0.

  Zu [*], "==>": Siehe Bourbaki, Algebra I, Chapters 1 bis 3, Seite 519.

  Siehe auch
  http://math.stackexchange.com/questions/71740/necessary-and-sufficient-condition-for-trivial-kernel-of-a-matrix-over-a-commuta und
  http://math.stackexchange.com/questions/161523/does-an-injective-endomorphism-of-a-finitely-generated-free-r-module-have-nonzer.

* McCoys Theorem: Sei A eine injektive (n x m)-Matrix über einem beliebigen
  Ring. Dann ist das Ideal (Lambda^m A) regulär.
  (Insbesondere: Falls n < m, so ist 0 = 1 in A.)
  http://www2.im.uj.edu.pl/actamath/PDF/30-215-218.pdf

  Sei a (Lambda^m A) = (0). Wir möchten zeigen, dass a = 0.
  Dazu zeigen wir rückwärts-induktiv, dass a (Lambda^k A) = (0)
  für alle k = 0, ..., m. Sobald wir den Fall k = 0 bewiesen haben, sind wir
  fertig. Der Fall k = m ist Voraussetzung.

  Sei also 0 <= k <= m - 1 und gelte a (Lambda^(k+1) A) = (0).
  Sei M ein k-Minor von A, ohne Einschränkung der der ersten k Zeilen und
  Spalten von A. Es gibt dann noch eine weitere Spalte in A, da m >= k + 1.
  Sei für j = 1, ..., k+1 die Zahl M_j der Minor der ersten (k+1) Spalten von A
  ohne die j-te. Insbesondere ist M_(k+1) = M.

  Dann ist a A (M_1 | -M_2 | ... | (-1)^(k+1) M_(k+1) | 0 | ... | 0)^T = 0.
  Denn wenn man das ausmultipliziert, stehen lautet Determinanten da.
  Die ersten k Stück verschwinden, weil sie zwei gleich Zeilen enthalten. Die
  anderen verschwinden nach Induktionsvoraussetzung.

  Da A injektiv ist, folgt somit a M_i = 0 für alle i = 1, ..., k+1,
  insbesondere also a M = 0.

* Korollar: Sei A eine quadratische injektive Matrix. Dann ist ihre
  Determinante regulär.

* Korollar: Sei M ein Modul, der ein Erzeugendensystem der Länge n
  und eine linear unabhängige Familie der Länge n enthält. Dann ist
  das Erzeugendensystem schon eine Basis. (Die linear unabhängige Familie nicht
  unbedingt.)

  Schreibe pi : A^n --> M für das Erzeugendensystem und iota : A^n --> M
  für die linear unabhängige Familie. Wir finden dann eine Abbildung
  alpha : A^n --> A^n mit pi . alpha = iota. Da iota injektiv ist,
  ist auch alpha injektiv. Somist ist det(alpha) regulär. Wenn wir det(alpha)
  invertieren, ist alpha also bijektiv. Somit ist pi dann injektiv.
  Da det(alpha) regulär ist, ist pi auch wirklich injektiv. Somit ist pi
  bijektiv, also eine Basis.

* Korollar: Seien v_1, ..., v_m Spaltenvektoren. Genau dann ist diese
  Familie linear unabhängig, wenn das Element v := (v_1 ^ ... ^ v_m) aus
  Lambda^m(A^n) regulär ist.

  "<==": Sei sum_i a_i v_i = 0. Dann ist a_i v = 0. Also a_i = 0. Geht für alle i.

  "==>": Das Element v gibt im Wesentlichen nur die m-Minoren der Matrix
  (v_1|...|v_m) wieder. Also folgt das aus McCoys Theorem.

* Richmans schöner Beweis dass Injektionen A^n --> A^m schon n <= m oder 1 = 0
  haben müssen hat Konkurrenz:
  http://mathoverflow.net/questions/136/atiyah-macdonald-exercise-2-11/47846#47846
  http://math.stackexchange.com/questions/20178/given-a-commutative-ring-r-and-an-epimorphism-rm-to-rn-is-then-m-geq-n

* Sei A eine (p x q)-Matrix über einem Ring R. Sei E ein R-Modul. Dann gibt es
  folgende Ergebnisse (Northcott, Thm. 6, Seite 63f.) über die Lösbarkeit von
  "A w = 0 in E" (wobei w ein Vektor der Länge q aus Elementen von E ist).

  * Sei Aw = 0. Dann gilt (Lambda^q A) w_i = 0 für alle i.

    Insbesondere: Ist ein Element w_i nicht Null, so gibt es in dem Untermodul
    (0 : (Lambda^q A)) ein nicht-Null-Element. Genauso mit "linear unabhängig"
    oder "invertierbar" (im Fall E = R).

    Außerdem folgt: Ist das Ideal der q-Minoren für E regulär (d.h. folgt aus
    (Lambda^q A) v = 0 schon v = 0 für Elemente v von E), so ist A als
    Abbildung E^q --> E^p injektiv.

  * Existiere ein Modulelement v und eine Zahl nu <= q - 1, sodass:
    1. ein nu-Minor Delta mit Delta e != 0 existiert und
    2. (Lambda^(nu+1) A) v = 0.
    Dann gibt es einen Vektor v, der eine Komponente besitzt, die bis auf
    Vorzeichen mit Delta e übereinstimmt, und für den Av = 0 gilt.

  Spezialfall E = R, R diskret: Genau dann gibt es einen Vektor z mit Az = 0,
  der mindestens eine Nicht-Null-Komponente enthält, wenn es ein Ringelement e
  und eine natürliche Zahl i <= q - 1 gibt, sodass mindestens ein i-Minor mit e
  multipliziert nicht Null ist und e * (Lambda^(i+1) A) = (0) ist. Die
  Rückrichtung geht auch ohne Diskretheit.

  Unter der Annahme, dass jedes Element invertierbar oder nicht invertierbar
  ist und nicht-invertierbare Elemente Null sind, gilt auch: Genau dann
  gibt es einen Vektor z mit Az = 0, der mindestens eine invertierbare Komponente
  enthält, wenn es eine Zahl i <= q - 1 gibt, sodass mindestens ein i-Minor
  invertierbar ist und (Lambda^(i+1) A) = (0) ist. Die Rückrichtung geht auch ohne
  Voraussetzungen.

  In Minimallogik gilt für beliebige Ringe mit 1 != 0:
  Genau dann existiert nicht nicht ein Vektor z mit Az = 0, der mindestens eine
  Nicht-Null-Komponente hat, wenn nicht nicht eine Zahl i <= q - 1 und ein
  Ringelement e existiert, sodass  mindestens ein i-Minor mit e multipliziert
  nicht Null ist und e * (Lambda^(i+1) A) = (0) ist.


=== Quotientenmoduln

* Sei A ein lokaler Ring. Sei M ein A-Modul frei von endlichem Rang.
  Dann ist die Kategorie der freien Quotientenmoduln von M, die von einem
  festen vorgegebenen Rang sind, sogar schon ein Gruppoid. Denn eine
  lineare Abbildung Q --> Q' über M ist automatisch surjektiv und hat (da A
  lokal) somit trivialen Kern, ist also auch injektiv.

* Sei ein Diagramm der Form

      A  --> B  --> C --> 0  (exakt)
             |
             v
             B' --> C'

  gegeben. Dann existiert genau dann ein Morphismus C --> C', der das rechte
  Quadrat kommutieren lässt, wenn die Komposition A --> B --> B' --> C' Null ist.
  Das liegt einfach an der Linksexaktheit von Hom(__, C').


=== Eigenvektoren

* Sei det(M) = 0. Unter welchen Voraussetzungen gibt es dann einen
  Vektor v im Kern von M, welcher (in welchem Sinn?) nichttrivial ist?

  Anwendung: M könnte eine fast-komplexe Struktur auf einer Mannigfaltigkeit
  sein.


=== Ganzheit

* Sei A --> B ein Ringhomo. Dann sind äquivalent:

  (1) B endlich über A.
  (2) B ganz und als Algebra endlich erzeugt über A.

  Beweis:
  (1) ==> (2): Ganzheit folgt aus Cayley--Hamilton.
  (2) ==> (1): Brauche wegen Ganzheitsgleichungen nicht beliebige Potenzen der
  Erzeuger.

  Es gilt auch: Ist B als A-Modul endlich präsentiert, so ist B als A-Algebra
  endlich präsentiert und ganz. (Nimm ein Erzeugendensystem (x_1,...,x_n) von B
  als A-Modul. Sei der Relationenmodul von sum_i a_ij x_i = 0 erzeugt. Finde
  Koeffizienten 1 = sum_i b_i x_i und x_i x_j = sum_k c_ijk x_k. Dann ist B
  als A-Algebra isomorph zu A[X_1,...,X_n]/(...alle aufgeführten Dinge mit
  Großbuchstaben...).

  Auch die Rückrichtung gilt: Ist B als A-Algebra endlich präsentiert und ganz,
  so ist B auch als A-Modul endlich präsentiert. Das ist nicht völlig trivial.
  Tag 0564.

* Sei B eine A-Algebra, die als A-Modul endlich frei ist. Sei A lokal.
  Dann finden wir immer eine Basis, die das Einselement von B enthält.

* Sei B als Modul endlich über A. Sei A in B ganz abgeschlossen. Dann ist B = A:
  Sei z in B. Dann ist z Nullstelle des charakteristischen Polynoms einer
  Matriz zur linearen Abbildung x |--> zx. Also liegt z in A.

* Sei phi : A --> B ein injektiver Ringhomo. Sei x aus A.
  Sei phi(x) invertierbar und sei phi(x)^(-1) ganz über A.
  Dann ist x auch invertierbar in A.

  Also: Injektive ganze Ringhomos sind lokal (reflektieren Invertierbarkeit).

  Und: Sei R --> S ein injektiver ganzer Ringhomo. Ist S ein Körper, so auch R.
  (In jedem der drei üblichen konstruktiven Sinne von "Körper".)

  Sowie: Sei R ein Integritätsbereich. Ist R --> Quot(R) ganz, so ist R schon
  ein Körper und der kanonische Morphismus ein Iso.

* Mit Noether-Normalisierung folgt: Sei A endlich erzeugte Algebra über einem
  Körper k und m ein maximales Ideal in A. Dann ist A/m eine endliche (!)
  Erweiterung von k.

  Somit: Eine Körpererweiterung ist genau dann endlich, wenn sie endlich
  erzeugt ist.

* Sei Z ein Ring und S ein multiplikatives System.
  Sei Q := Z[S^(-1)].
  Sei Q --> A ein ganzer Ringhomo.
  Dann habe den Ring O_A derjenigen Elemente aus A, die eine Ganzheitsgleichung
  über Z erfüllen. Da jedes Element x aus A von der Form ux/u ist, wobei u ein
  Element aus S und ux ein Element aus A ist, das ganz über Z ist, ist

      O_A[S^(-1)] --> A

  ein Iso.

  Insbesondere sind also die Quotientenkörper von Ganzheitsringen von endlichen
  Erweiterungen K von Q wieder gleich K.

* Sei A ein Integritätsbereich. Sei A <= B <= A-quer (ganzer Abschluss von A).
  Sei B ganz abgeschlossen (absolut oder in A-quer, das ist äquivalent, da
  Quot(B) = Quot(A-quer)). Dann ist schon A-quer = B.

* Sei K | Q ein Zahlkörper. Dann gilt auch konstruktiv: Eine K-Basis von O_K,
  welche ganz ist, ist genau dann eine Ganzheitsbasis, wenn der Betrag ihrer
  Diskriminante kleinst ist unter allen Beträgen von Diskriminanten von ganzen
  Q-Basen.

* Sei phi : R --> S ein injektiver Ringhomo. Sei x aus R. Sei phi(x)
  ganz über etwas. Dann ist auch x ganz darüber.

* Sei f(X) ein normiertes Polynom vom Grad mindestens 1. Dann ist der Ringhomo
  R --> R[X]/(f) injektiv.

* Sei p(X) ein normiertes Polynom, das ein weiteres normiertes Polynom f(X)
  teilt. Seien alle Koeffizienten von f(X) über irgendeinem Ring ganz. Dann
  sind auch alle Koeffizienten von p(X) ganz, und zwar bezeugt von universellen
  Ganzheitsgleichungen (deren Koeffizienten universelle Polynome in den
  Koeffizienten von f(X), p(X) und den Koeffizienten der gegebenen
  Ganzheitsgleichungen sind). (mit Matthias erarbeitet)

  Der Beweis geht über das folgende Lemma, welches man auch auf die "generische
  Situation" anwenden kann: Z[A_i, B_j, D_k]/(Ganzheitsgleichungen) über Z[D_k].
  Dann ist p(X) = sum_i A_i X^i und f(X) = (sum_i A_i X^i) (sum_j B_j X^j).

* Sei f(X) ein Polynom aus R[X]. Genau dann sind alle Koeffizienten von f(X)
  ganz über irgendeinem Ring, wenn alle Nullstellen von f(X) (in irgendeinem
  Oberring Omega von R, über dem f(X) in Linearfaktoren zerfällt) ganz sind.
  (mit Matthias erarbeitet)

  "==>": Klar. Wäre sogar richtig für "Oberringe", in die R nicht injektiv
  einbettet.

  "<==": Die Linearfaktoren haben ganze Koeffizienten. Damit sind die Bilder
  der Koeffizienten von f(X) in dem Oberring jeweils ganz. Wegen der
  Injektivität sind auch schon die Koeffizienten selbst ganz.

  Auch dieses Lemma liefert universelle Formeln: Die Koeffizienten der
  Ganzheitsgleichungen der Koeffizienten von f(X) sind universelle Polynome in
  den Koeffizienten der gegebenen Ganzheitsgleichungen.

  Das zeigt man wohl durch Betrachtung des folgenden "Spezialfalls":

      S     = Z[D_jk]
      R     = Z[A_i, D_jk]
      Omega = (Zerfällungsalgebra von sum_i A_i X^i)/(die D_jk sind
      Koeffizienten von Ganzheitsgleichungen für die Nullstellen von sum_i A_i X^i)


=== Noether-Normalisierung konstruktiv

* Ist f ein Polynom in mehreren Variablen, kann man durch einen
  Automorphismus erreichen, dass der Leitkoeffizient des Polynoms, aufgefasst
  als Polynom in der letzten Variable, ein Element des Grundrings ist (statt
  ein Element des um eine Variable verkürzten Polynomrings).

* http://www.math.lsa.umich.edu/~hochster/615W10/supNoeth.pdf
  Noether-Normaliserung für Integritätsbereiche

* http://math.uchicago.edu/~keerthi/files/CA.pdf
  Kapitel 8, empfohlen von Pete Clark


=== Torsion

* M_tors = { x : M | exists a. a regulär und ax = 0 }.

* M torsionsfrei :<==> M_tors = 0.

* M Torsionsmodul :<==> M = M_tors.

* M Torsionsmodul <==> M tensor_A A[reg^(-1)] = 0 <==> M[reg^(-1)] = 0.

* M^ ist stets torsionsfrei.

* M reflexiv ==> M torsionsfrei.

* A/(d) Torsionsmodul <==> 1 \in A/(d) Torsionselement <==> d regulär.

* A/(d) torsionsfrei <== d = 0 oder d inv.
  Falls A starker Integritätsbereich ist, gilt auch "==>".

* Eine direkte Summe ist genau dann torsionsfrei, wenn alle Summanden
  torsionsfrei sind. Genauso mit Torsionsmoduln.

* Sei 0 --> M' --> M --> M'' --> 0 eine kurze exakte Sequenz,
  wobei die vorderen beiden Moduln frei vom Rang 1 sind. Dann ist M'' ein
  Torsionsmodul.

* Angeblich: M endlich präsentiert ==> M^ reflexiv.

* Angeblich: Kerne von linearen Abbildungen zwischen endlich freien Moduln sind
  reflexiv.

* Sei M ein A-Modul. Sei S eine multiplikative Teilmenge von A. Dann gilt:

      Ist S <= Reg, so S^(-1) M_tors = (S^(-1) M)_tors.

  Ist x/s aus der linken Seite gegeben, so ist x/s auch als Element der rechten
  Seite ein Torsionselement, denn das reguläre Element von A, das als Zeuge
  dient, ist auch als Bruch mit Nenner 1 in S^(-1) A regulär.

  Ist umgekehrt x/s aus der rechten Seite gegeben, so gibt es ein Element a von A,
  das als Einsbruch regulär ist. Nach Voraussetzung an S ist es damit auch als
  Element von A regulär. Es gilt ax = 0 als Einsbrüche, also uax = 0 in M.
  Somit können wir x/s auf ux/us schicken.

* Sei E so, dass E_tors endlich erzeugt ist. Dann gilt:

      dim E_tors := dim A/ann(E_tors) <= dim A - 1.

  Denn: Ich finde ein reguläres Element s aus A mit s E_tors = 0.
  Somit (s) <= ann(E_tors). Die Behauptung folgt, da dim A/(s) <= dim A - 1
  und dim E_tors <= dim A/(s), da wir die Surjektion O_X/(s) -->
  O_X/ann(E_tors) haben.

  Angeblich ist E_tors maximal mit dieser Eigenschaft. (Huybrechts/Lehn über
  Modulräume von Garben, Seite 4 oben.)


=== Skalareinschränkung und Skalarerweiterung

Sei phi : A --> B ein *surjektiver* Ringhomo.

Sei M ein B-Modul. Dann ist M \otimes_A B kanonisch B-isomorph zu M.
(So wird vermutlich B-Mod eine volle Unterkategorie von A-Mod.)

Folgendes stimmt aber nicht: Sei N ein A-Modul. Dann ist N \otimes_A B
kanonisch A-isomorph zu N.

* Skalarerweiterung längs phi -| Skalareinschränkung -| Hom_A(B, __).

* Übrigens: Habe nicht nur Z --> Z[G], sondern auch Z[G] --> Z.
  (Kann mir Z[G] als Z[X^g | g in G]/(X^g X^h - X^gh, X^1 - 1) denken.)

  Somit habe Koinvarianten -| mit trivialer G-Wirkung ausstatten -|
  Invarianten. (Koinvarianten nehmen ist Tensorieren mit Z über Z[G]. Finde die
  Koendeformel dazu sehr schön. :-))


=== Zusammenhang zu Vektorbündeln

Prop. (Thm. 7.22 in http://math.uga.edu/~pete/integral.pdf):
    Sei M ein A-Modul. Dann sind äquivalent:
    (1) M ist endlich erzeugt und projektiv.
    (2) Es gibt eine Zerlegung 1 = \sum_i f_i der Eins, sodass
        jeder Modul M_(f_i) ein freier A_(f_i)-Modul endlichen Rangs ist.

Also: M~ lokal frei <==> M erfüllt (2) <==> M erfüllt (1).

Außerdem: Ein Modul mit (1) ist automatisch auch endlich präsentiert. Denn ist
pi : A^n --> M eine Surjektion, so ist ker(pi) ein direkter Summand von A^n,
daher ein Quotient von A^n und somit endlich erzeugt.

Die Proposition stimmt auch völlig konstruktiv. Hier ist ein Beweis.

(1) ==> (2). M ist Kokern einer idempotenten Matrix P. Lokal ist diese von der
Form diag(1,...,1,0,...,0). Also ist M lokal endlich frei.

(2) ==> (1). M ist lokal endlich erzeugt, also endlich erzeugt. Sei A^n --> M
eine Surjektion. Ihr Kern ist lokal endlich erzeugt, da M lokal endlich
präsentiert sind. Also ist ihr Kern auch global endlich erzeugt. Somit ist M
endlich präsentiert.

Damit vertauscht Hom(M, __) mit Lokalisierung.

Sei nun X --> Y eine surjektive Abbildung. Wir wollen zeigen, dass
Hom(M, X) --> Hom(M, Y) surjektiv ist. Lokal ist das klar.


Es gibt auch folgende Äquivalenz:

(a) Jede idempotente Matrix ist äquivalent zu einer Diagonlmatrix mit Einträgen 0 und 1.
(b) Jede idempotente Matrix ist ähnlich zu einer Diagonlmatrix mit Einträgen 0 und 1.
(c) Jeder lokal endlich freie Modul ist endlich frei.

(a) ==> (b): Klar. Finde nämlich Basen von ker(P) und im(P).

(b) ==> (c): Lokal endlich freie Moduln sind Kokerne (oder Kerne, oder Bilder)
von idempotenten Matrizen.

(c) ==> (a): Nach Voraussetzung sind ker(P) und im(P) endlich frei. Finde also
Basen. Fertig.


=== Dualisieren

* Habe stets Hom_A(M, N) --> Hom_A(N^, M^).
  Wenn die kanonischen Abbildungen M --> M^^ und N --> N^^ Isos sind,
  ist das ebenfalls ein Iso.

* Falls M frei von endlichem Rang ist, ist M --> M^^ ein Iso.


=== Länge von R-Moduln

Definition: len M = sup { n | ex. U_0 < ... < U_n <= M Kette von Untermoduln }.
Kann oBdA fordern U_0 = 0, U_n = M.

Beispiele:
* Falls M Vektorraum über einem Körper: len M = dim M.
* len M = 0  <==>  M = 0.
* len M = 1  <==>  M einfach.
* len R kann unendlich sein, etwa für R = Z.

Proposition: Sei 0 --> M' --> M --> M'' --> 0.
Dann len M < infty <==> len M', len M'' < infty und
die Länge verhält sich additiv.

Beispiel: Sei R ein Hauptidealbereich. Dann ist die Länge von R/(a)
gleich der Gesamtzahl irreduzibler Faktoren in a.
(Bem.: R-Untermoduln von R/(a) sind dasselbe wie Ideale des Rings R/(a).)

* Sei A ein noetherscher lokaler Ring und zugleich eine Algebra über
  einem Körper k. Sei M ein endlich erzeugter A-Modul.
  Dann gilt len_A(M) * dim_k(A/m) = dim_k(M). (Liu Ex. 7.1.6, Seite 264; oder
  letzte Algebra II, Blatt 10. Es ist A/m endlich dimensional als
  k-Vektorraum, wenn A von endlichem Typ über k ist.)

* Präzisere Formulierung: Sei A eine endlich erzeugte lokale Algebra über einem
  Körper k. Sei M ein A-Modul. Genau dann ist M noethersch und artinsch
  (d.h. besitzt endliche Länge), wenn M als k-Vektorraum endlich dimensional
  ist. In diesem Fall gilt dim_k(M) = l_A(M) * dim_k(A/m), und die Dimension
  von A/m ist endlich wegen Noether-Normalisierung.

* Sei A eine endlich erzeugte Algebra über einem Körper k. Genau dann ist A
  als Ring artinsch, wenn A als k-Vektorraum endlich dimensional ist. (Zeigt
  man mit dem Struktursatz für artinsche Ringe.)

* Sei auf dem K^n eine lineare Abbildung mit Jordanbasis a_1,...,a_n gegeben.
  Dann bilden die Untermoduln <a_1,...,a_i> eine Kompositionsreihe von K^n als
  K[X]-Modul. Es spielt dabei keine Rolle, ob der K-Spann oder der K[X]-Spann
  genommen wird. Die Jordaneinser müssen oberhalb der Diagonale stehen.
  Insbesondere ist die Länge von K^n als K[X]-Modul in diesem Fall n.

  Falls es nur eine Weierstraßbasis gibt, fällt die Länge entsprechend kürzer
  aus.

* Sei A --> B ein surjektiver Ringhomo. Sei M ein B-Modul. Dann ist seine Länge
  als B-Modul gleich seiner Länge als A-Modul.


=== Einfache Moduln

Da ich nicht weiß, was eine "gute" Definition von Einfachheit in einem
konstruktiven Kontext ist, kann ich das Folgende nur klassisch behaupten.

Proposition: Sei M ein einfacher A-Modul. Dann ist M unkanonisch isomorph zu
A/m für ein maximales Ideal m.

Beweis: Habe ein x in M, x ungleich null. Erhalte A --> M. Erhalte A/ker --> M.
Muss ein Iso sein. Ferner folgt, dass der Kern schon ein maximales Ideal sein
muss.


=== Lokalisierung

* Sei A ein Integritätsbereich. Genau dann ist A[S^(-1)] ein Integritätsbereich,
  wenn 0 nicht in S liegt.

* Sei A ein Ring, p ein Primideal und x in A. Dann:

      x regulär in A_p <==> [xy = 0 in A ==> ex. z \not\in p: zy = 0] f.a. y

* Äquivalent sind:

  1. Spec(A) |== AA --> AA[F^(-1)] ist injektiv
  2. Für alle a, b aus A gilt: ab = 0  ==>  a = 0 oder b nilpotent.
  3. (klassisch) Alle A --> A_p sind injektiv.
  4. (klassisch) Jeder Nullteiler ist schon nilpotent.

  Folglich ist das Nullideal von A genau dann ein Primärideal, wenn diese
  Aussagen gelten und wenn zusätzlich 1 != 0 ist.

  Insbesondere sind diese Aussagen für (starke und auch schwache)
  Integritätsbereiche erfüllt.

* Sei iota : A --> A[S^(-1)] die Lokalisierung an einem *saturierten* multiplikativ
  abgeschlossenen System (d.h. xy in S ==> x in S und y in S). Dann ist iota(x)
  genau dann invertierbar, wenn x in S liegt. (Sonst gilt nur "<==".)

* Der kanonische Morphismus iota : A --> A[S^(-1)] ist genau dann ein
  Isomorphismus, wenn alle Elemente aus S invertierbar sind.

* Ein Element x aus A ist genau dann in A[f^(-1)] invertierbar, wenn
  f in sqrt((x)).

* Die Menge der regulären Elemente eines Rings ist immer ein saturiertes
  multiplikativ abgeschlossenes System.

* M[S^(-1)] ist der filtrierte Kolimes von folgendem System:

      Indexkategorie:

          Objekte s \in S, Morphismen: Hom(s,t) = { u in S | t = su }.

      Diagramm:

          s |--> M
          u |--> (M --> M, Multiplikation mit u).

  Speziell für S = { f^0, f^1, ...} ist die Lokalisierung also der Kolimes von

      M ---> M ---> M ---> ...   (jeweils Multiplikation mit f).

  Insbesondere:

      Hom_A(A[f^(-1)], M) ~~ { (x_0,x_1,...) | x_i in M, x_n = f x_{n+1} }.

* Gehört hier nicht hin, aber trotzdem:

      Hom_A((f), M) ~~ { u in M | forall h:A. hf = 0 ==> hu = 0 }

* Sei (s_i) eine Zerlegung der Eins in einem Ring A. Dann ist A der
  inverse Limes von A[s_i^(-1)] --> A[s_i^(-1), s_j^(-1)]. (Sagt Lombardi in
  Oberwolfach2.pdf. Außerdem ist es recht klar, da das eigentlich nur die
  bekannte Differenzkernbedingung an die Strukturgarbe von Spec A ist.)

  Als Korollare erhält man: Nullheit und Invertierbarkeit von Ringelementen
  kann man lokal testen; Elemente kann man lokal angeben; Ringhomos kann man
  lokal konstruieren.

  Außerdem kann man viele Eigenschaften lokal testen; Lombardi gibt unter
  anderem an: Kohärenz, Normalität, Prüferität, (bei Algebren) endlich erzeugt,
  endlich präsentiert, glatt, unverzweigt, ...

  Analoges gilt für Moduln und für Rahmen/distributive Verbände.

* Sei S eine multiplikativ abgeschlossene Menge in einem Ring A. Dann ist

      Sat(S) := { x in A | ex. f in S: f in sqrt(x) }
              = { x in A | ex. y in A: xy in S }

  ihre Saturierung, d.h. die kleinste multiplikativ abgeschlossene und
  saturierte Menge, welche S umfasst.

  Im Spezialfall S = { f^0, f^1, ... } ist Sat(S) = { x | f in sqrt(x) }.

* Sei A ein graduierter Ring und S ein multiplikativ abgeschlossenes
  System, das nur aus homogenen Elementen besteht. Dann ist der lokalisierte
  Ring A[S^(-1)] auf kanonische Art und Weise wieder ein graduierter Ring.

  Dabei heißt ein Element z genau dann homogen vom Grad n, wenn es als Bruch
  geschrieben werden kann, dessen Zähler homogen ist und um n höheren Grad hat
  als der Nenner.

  Obacht: Auch wenn A N-graduiert ist, ist A[S^(-1)] im Allgemeinen
  Z-graduiert!

* Sei m ein maximales Ideal in einem Ring A. Dann gilt:

      A \ m = 1 + m.

  "<=": Sei x nicht in m. Dann ist m + (x) = (1), also gibt es
  ein Element u aus m mit u + x = 1. Also gilt x = 1 + (-u).

  ">=": Klar.

  Umgekehrt ist ein Ideal m, für das A \ m = 1 + m ist, schon maximal.
  Denn sei y nicht in m. Dann gibt es ein u aus m mit y = 1 + u,
  also 1 = u + (-y), also m + (y) = (1).

  Also ist A[(1+m)^{-1}] ein schöner Ersatz für A_m, wenn ich von m nur
  klassisch weiß, dass es ein maximales Ideal ist!

  Könnte auch ein Indiz dafür liefern, wie die Örtlichkeit der minimalen Filter
  zu definieren sei.

* Lokalisieren vertauscht nicht mit Vervollständigung. Im Allgemeinen
  ist der kanonische Morphismus

      A^_a[f^{-1}] ---> A[f^{-1}]^_a

  kein Iso. Zum Beispiel sei A = k[X], a = (X) und f = X. Dann ist die linke
  Seite k[X,X^{-1}], aber die rechte Null.


=== Lokale Ringe

* Sei (A,m) lokal. Dann ist A --> A/m ein lokaler Homo:

  Sei [x] in A/m invertierbar. Dann gibt es y in A mit xy - 1 in m.
  Da A lokal ist, ist xy oder 1-xy invertierbar. Also Fall 1. Also ist x
  invertierbar.

* Sei (A,m) ein lokaler Ring. Sei M ein freier A-Modul vom Rang 1.
  Sei s in M. Dann gilt:

      A --s--> M ist genau dann ein Iso, wenn s != 0 in M/mM.

  "==>" ist klar, tensoriere.
  "<==" folgt durch Betrachtung der Determinante dieser Abbildung: Diese wird
  nämlich invertierbar nach Tensorieren mit A/m.

  Damit folgt: Sei s ein globaler Schnitt eines Geradenbündels L.
  Dann s_x : O_{X,x} --> L_x genau dann ein Iso, wenn s != 0 in L|_x.

* http://www.math.iitb.ac.in/atm/caag1/jayanthan.pdf

* Jacobi-Kriterium impliziert Regularität, unter gewissen Voraussetzungen:
  Computational Methods In Commutative Algebra And Algebraic Geometry, Seite 131.

* Sei M ein endlich-erzeugter A-Modul, A lokaler Ring.
  Dann gilt: Hom_A(M, A/m) = 0 ==> M = 0.

  Denn: Wähle eine (A/m)-Basis von M/mM. Dann habe die Dualbasisabbildungen
  M/mM --> A/m. Nach Voraussetzung sind die aber alle Null (M --> M/mM ist ja
  surjektiv). Also ist die Basis leer. Damit sind M/mM und M Null.

* Sei M ein A-Modul, A lokaler Ring. Ist M frei, so ist Ext^1(M, A/m) = 0.
  Klar, denn dann ist M projektiv.

  Die Umkehrung gilt ebenfalls, falls M endlich erzeugt und A noethersch ist.
  Denn dann folgt aus einer kurzen exakten Sequenz 0 --> K --> A^n --> M --> 0,
  dass 0 --> Hom(M, k) --> Hom(A^n, k) --> Hom(K, k) --> 0 exakt ist.

  Die Einschränkung einer Abbildung A^n --> k auf m A^n (insbesondere auf K,
  denn K <= m A^n) ist Null. Also ist Hom(K, k) = 0. Also ist, nach dem
  vorherigen Punkt, K = 0. Hier geht ein, dass A noethersch ist: Denn sonst
  wüssten wir nicht, dass K wieder endlich erzeugt ist.

* Sei I ein endlich erzeugtes idempotentes Ideal eines lokalen Rings A.
  Dann ist I = (0) oder I = (1). Denn nach dem Lemma von Nakayama, angewendet
  auf den A-Modul I und das Ideal, gibt es ein a aus A mit a = 1 mod I und a I = 0.
  Da A lokal ist, ist a invertibar oder 1-a invertierbar. Im ersten Fall ist I = (0),
  im zweiten I = (1).

* Sei M ein endlich erzeugter projektiver Modul über einem lokalen Ring A.
  Dann ist M Kokern einer idempotenten Matrix P. Die Gleichung P^2 = P
  überträgt sich auf Lambda^i(P). Also sind alle Fitting-Ideale von P
  idempotent, somit jeweils (0) oder (1). Also ist M frei von einem gewissen
  Rang.

  Der Beweis zeigt auch, dass P über Zeilen- und Spaltenumformungen auf die
  Form diag(1,...,1,0,...,0) gebracht werden kann. Eigentlich sollte doch auch
  noch mehr drin sein, oder nicht? Ja. Finde dadurch nämlich explizit eine
  Basis von ker(P) und im(P) und damit von A^n. Bezüglich dieser Basen im
  Quell- *und* Zielraum hat P auch die Form diag(1,...,1,0,...,0).

* Sei phi : A --> R ein Ringhomo. Dann faktorisiert phi auf genau eine Weise
  (bis auf Isomorphie) in eine Lokalisierung gefolgt von einem lokalen
  Ringhomo. Anders gesagt: Es gibt genau ein saturiertes multiplikatives System
  in A (nämlich S = { x in A | phi(x) invertierbar }), sodass phi über
  A --> A[S^(-1)] faktorisiert und der entstehende Ringhomo A[S^(-1)] --> R
  lokal ist.

  Beweis: Zunächst ist klar, dass die angegebene Setzung von S das erfüllt.
  Sei zum Nachweis der Eindeutigkeit ein beliebiges saturiertes System S,
  das die Anforderungen erfüllt, gegeben.

  Dann sind die Elemente aus S alle in R invertierbar, einfach trivialerweise,
  weil phi über A[S^(-1)] faktorisiert. Umgekehrt ist auch jedes Element x aus A,
  sodass phi(x) invertierbar ist, ein Element von S. Denn x/1 ist wegen der
  Lokalität der Faktorisierung in A[S^(-1)] invertierbar.

  Zusatz: Ist R lokal, so ist S ein Filter, erfüllt also noch die Axiome
  1 \not\in S und (x + y in S ==> x in S oder y in S) erfüllt. Die Umkehrung
  gilt nicht.


=== Äußere Algebra

* Habe Lambda^(n+1) R^n = 0 konstruktiv, aus rein kombinatorischen Gründen.

* Habe Lambda^n R^n --> R (Iso) konstruktiv, vermöge der Determinante.

* Sei 0 --> F' --> F --> F'' --> 0 exakte Sequenz freier Moduln.
  Dann habe (det F') tensor (det F'') --> det F Iso, explizit gegeben durch

      x_1 ^ ... ^ x_n  tensor  y_1 ^ ... ^ y_m
          |--> i(x_1) ^ ... ^ i(x_n) ^ a_1 ^ ... ^ a_m,
              wobei p(a_j) = y_j (Wahl spielt keine Rolle).

* Die Determinante verhält sich multiplikativ in exakten Sequenzen
  freier Moduln. (Siehe auch Vakil, 13.5.H, "determinant line bundles behave
  well in exact sequences".)

* Habe eine Filtrierung auf Lambda^r(F), wenn F der Mittelteil einer kurzen
  exakten Sequenz ist. Siehe Vakil, aber noch prüfen, insbesondere auf
  konstruktive Zulässigkeit.

* Habe Lambda^i(V) tensor W^(tensor i) --> Lambda^i(V tensor W),
  falls W vom Rang 1. Diese Abbildung bildet die offensichtliche Basis
  auf die offensichtliche Basis ab und ist daher ein Iso.

* http://www.math.uni-bielefeld.de/~hkrause/koszul.pdf über äußere Algebra,
  symmetrische Algebra usw. Außerdem wie man diese Algebren richtig definiert:
  http://math.stanford.edu/~conrad/diffgeomPage/handouts/tensor.pdf

* Habe in jeder Charakteristik natürliche lineare Abbildungen

      Lambda^n V^ --> (Lambda^n V)^
           S^n V^ --> (S^n V)^,

  gegeben durch die Determinante bzw. Permanente (d.h. durch geeignet
  gewichtete Summen über alle Permutationen). Die erste Abbildung ist stets ein
  Iso (falls V endlich frei). Die zweite nicht.

* Ziemlich sicher gilt: Lambda^n_A M tensor_A A/J = Lambda^n_{A/J}(M tensor_A A/J).
  Sogar für allgemeine Skalarerweiterungen. Siehe zum Beispiel
  http://therisingsea.org/notes/TensorExteriorSymmetric.pdf.

* Jeder Vektor in Lambda^2(R^3) ist rein.

* https://xorshammer.com/2016/05/09/youtube-physics-explanations-shouldnt-use-the-right-hand-rule/
  Statt vec(r) x vec(p) zu nehmen, kann man auch einfach vec(r) wedge vec(p)
  betrachten. Addition durch Aneinanderhängen von Parallelogrammen längs zweier
  gleich langer Kanten.


=== Verklebung von Modulkategorien

Siehe Tag 05N9 im Stacks-Projekt: Die Kategorie der R-Algebren ist der Kolimes
der Kategorie der R_i-Algebren, wenn R = colim_i R_i ein filtrierter Kolimes
von Ringen ist.
  

=== Duale Zahlen

Sei A ein Ring. Dann heißt A[eps]/(eps^2) der Ring der dualen Zahlen über A.

* a + b eps ist genau dann invertierbar, wenn a invertierbar in A ist.

  Das Inverse ist dann a^(-1) - a^(-2) b eps.

* Ist A lokal, so auch A[eps]/(eps^2). Die Umkehrung gilt auch.

* Siehe deformationen.txt für Flachheit über A[eps].


=== Freiheit und Flachheit über Z

* Eine Z-Algebra K, die ein Körper der Charakteristik != 2 ist, kann nicht frei
  sein. Sei b eines der Basiselemente. Stelle dann b/2 über die Basis dar. Dann
  multipliziere mit 2. Auf der rechten Seite steht dann eine gerade Anzahl b's.
  Bringe das b von der linken Seite auf die rechte. Dann steht eine
  nichttriviale Relation da (da die Anzahl b's ungerade ist).

  (Körper mit Charakteristik 2 sind natürlich auch nicht frei.)

* Daher ist auch kein Körper mit Char. != 2 projektiv über Z:
  Denn Untermoduln freier Z-Moduln wären frei. [Kann man das auch konstruktiv zeigen?]

* Q ist flach über Z: Sei a^T m = 0, a aus Z^p, m aus Q^p. Dann finde ein u
  aus Z\{0} mit u*m in Z^p. Dann gilt a^T (u*m) = 0 und (u*m) * (1/u) = m.

* Daher ist jeder Körper K der Charakteristik 0 flach über Z: Habe Z --> Q --> K.
  Q ist flach über Z (von oben) und K ist flach über Q, da Q ein Körper ist.

* Allgemeine Bemerkung: Surjektive Ringhomos sind im Allgemeinen NICHT flach.
  Gegenbeispiel: Z --> Z/(2).

* Z/(n) ist nicht flach über Z, denn zum Beispiel bleibt die Injektion
  Z --> Q unter Tensorieren mit Z/(n) nicht injektiv.


=== Projektive Moduln

* Über die Charakterisierung von projektiven Moduln als direkte Summanden
  freier Moduln kann man leicht zeigen: Das Tensorprodukt projektiver Moduln
  ist wieder projektiv.

* Ist A ein nichtkommutativer Ring und e ein idempotentes Element, so ist
  Ae ein projektiver A-Links-Modul. Das kann man direkt sehen oder daran
  festmachen, dass Ae ein direkter Summand von A ist: A = Ae oplus A(1-e).

* Unterschied zu reflexiven Moduln: http://mathoverflow.net/a/7588
  As you say, a finite projective module is the same as a locally free sheaf on
  Spec R. Similarly, a finite reflexive module is the same as the push forward
  of a locally free sheaf from an open subset U of Spec R whose complement has
  codimension ≥2.

  http://mathoverflow.net/questions/7490/differences-between-reflexives-and-projectives-modules

* Ein A-Modul M ist genau dann projektiv und endlich erzeugt, wenn
  es Elemente x_1,...,x_n aus M und eta_1,...,eta_n aus M^ mit
  x = sum_i eta_i(x) x_i für alle x aus M gibt. ("Dual basis lemma")
  (Automatisch folgt dann für eta aus M^: eta = sum_i eta_i eta(x_i).
  Denn setzt man in die rechte Seite ein beliebiges x ein, so erhält man:
  sum_i eta_i(x) eta(x_i) = sum_i eta(eta_i(x) x_i) = eta(sum_i eta_i(x) x_i) =
  eta(x). Nicht folgen tut eta_i(x_j) = delta_ij. Deswegen müssen weder die x_i
  noch die eta_i linear unabhängig sein.)

  Eine Richtung zeigt man so: Gegebene Erzeuger induzieren eine surjektive
  Abbildung A^n -pi-> M. Wegen der Projektivität besitzt die
  Identitätsabbildung auf M einen Lift -- eine Abbildung rho : M --> A^n
  mit pi . rho = id. Setze dann eta_i := pi_i . rho.

  Als Folge ist übrigens M --> M^^ injektiv.

  Die andere Richtung geht so: Sei M mit x_i und theta_i. Sei f : T --> S
  eine A-lineare Surjektion. Sei g : M --> S. Wähle Urbilder f(t_i) = g(x_i).
  Dann definieren wir den Kolift

      g'(x) := sum_i theta_i(x) t_i.

  Dann gilt nämlich in der Tat f(g'(x)) = sum_i theta_i(x) f(t_i) =
  g(sum_i theta_i(x) x) = g(x).

* Sei M ein A-B-Modul. Dann sind folgende Aussagen äquivalent:
  1. Für einen B-A-Modul N gilt M -| N in der 2-Kategorie der Ringe
     (M : B -> A, N : A -> B).
  2. Für einen B-A-Modul N gibt es

          eps : N tensor_A M --> B  (B-B-linear)
          eta : A --> M tensor_B N  (A-A-linear)

     mit Meps . etaM = id_M und etaN . Neta = id_N.
  3. Für einen B-A-Modul N gibt es

          x_1, ..., x_n aus M und
          theta_1, ..., theta_n aus N und
          eps : N tensor_A M --> B  (B-B-linear)

     mit x = sum_i x_i eps(theta_i tensor x) und
     theta = sum_i eps(theta tensor x_i) theta_i für alle x aus M und theta aus N.
  4. Dieselbe Aussage wie in 3., nur mit N := Hom_B(M,B) und eps = ev.

  Zu 2 ==> 3: Erhalte die x_i und theta_i durch Betrachtung von eta(1).
  Zu 3 ==> 4: Habe den Iso N --> Hom_M(M,B) mit theta |-> eps(theta tensor __)
  und Umkehrung phi |-> sum_i phi(x_i) theta_i.

  All diese Aussagen sind ferner äquivalent dazu, dass M als Rechts-B-Modul
  endlich erzeugt und projektiv ist. Und übrigens ist die Äquivalenz 1,2,3 <==> 4
  einfach Spezialfall des allgemeinen Lemmas, dass Rechtsadjungierte durch
  Rechts-Kan-Erweiterung der Identität gegeben sind!

* Ist M projektiv und endlich erzeugt, so ist auch M^ projektiv und
  endlich erzeugt, und M --> M^^ ist sogar ein Iso.

* Ist M projektiv, so ist M direkter Summand eines freien Moduls.
  Also ist M Kokern einer idempotenten linearen Abbildung zwischen freien
  Moduln (d.h. einer Projektion!), nämlich von (id - iota . pi), wenn
  pi : A^(I) --> M und pi . iota = id.

  Beachte: cok P = ker P = im (Id - P).

  Auch die Umkehrung stimmt: Wenn M = cok P, P^2 = P, P linear zwischen freien
  Moduln, dann A^n = ker(1-P) oplus im(1-P) = ker(1-P) oplus cok(P).

* Endlich präsentierte flache Moduln sind projektiv. (Umgekehrt sind projektive
  Moduln stets flach.)
  http://cupid.economics.uq.edu.au/mclennan/Algebra/fac_trans.pdf, Thm. B9.11,
  Seite 90.

  Ein konstruktiver Beweis funktioniert so.

  Sei (x_1,...,x_n) ein Erzeugendensystem mit Präsentationsmatrix P.
  Da (P e_1)^T x = 0, finden wir B und y mit (P e_1)^T B = 0 und B y = x.
  Es ist also y ein neues Erzeugendensystem mit Präsentationsmatrix
  (B^T P | 1 - B^T C^T), wobei C eine Matrix mit C x = y ist. Die erste Spalte
  von B^T P ist Null.

  Dann verwenden wir die Flachheit für die Relation (B^T P e_2)^T y = 0.
  So finden wir ein neues Erzeugendensystem mit Präsentationsmatrix
  (B'^T B^T P | 1 - B'^T B^T C^T C'^T). Die ersten beiden Spalten von B'^T B^T P
  sind Null.

  Auf diese Weise können wir immer weiter machen. Schlussendlich erhalten wir
  ein Erzeugendensystem mit Präsentationsmatrix (B^T P | 1 - B^T C^T) (nach
  Umbenennung) und B^T P = 0. Da B C x = x, ist C^T B^T - 1 von der Form P V
  für eine Matrix V. Somit ist 1 - B^T C^T eine Projektionsmatrix:

      (1 - B^T C^T)^2 = 1 - B^T C^T - B^T C^T + B^T C^T B^T C^T = 1 - B^T C^T.
                                                \   \-----/
                                                 \    PV+1
                                                  ----/
                                                    0

  Somit wird der Modul durch die idempotente Matrix (1 - B^T C^T) präsentiert.
  Also ist der Modul projektiv.

* Beispiel für einen nichtfreien Modul, der mit einem endlichen freien Modul
  addiert einen endlich freien Modul gibt: Northcott, Appendix A.
  Lässt sich etwa über dem Ring der stetigen Funktionen auf S^2 oder
  Z[X,Y,Z]/(X^2+Y^2+Z^2-1) finden.


=== Flache Moduln

* Sei M ein endlich erzeugter flacher Modul über einem lokalen Ring.
  Dann besitzt jedes Erzeugendensystem eine Unterfamilie, welche eine Basis
  ist.
  http://cupid.economics.uq.edu.au/mclennan/Algebra/fac_trans.pdf, Prop. D5.2,
  Seite 140.

* Ein Modul ist genau dann flach, wenn er filtrierter Kolimes von freien Moduln ist.

  "<==": Filtrierte Kolimiten von freien (insb. flachen) Moduln sind
  flach, da das Tensorprodukt mit beliebigen (insb. filtrierten) Kolimiten
  verträglich ist und filtrierte Kolimiten von kurzen exakten Sequenz wieder
  exakt sind (in Modulkategorien).

  "==>": Angeblich ist M stets auf kanonische Weise der Kolimes aller endlich
  freien Moduln F --> M; und falls M flach ist, ist dieses System filtriert.
  Das behauptet Akhil Mathew in http://math.stackexchange.com/a/113112/61604,
  ich sehe das aber nur, wenn man schon hier die Flachheit von M voraussetzt.
  * Um die universelle Eigenschaft des Kolimes nachzuweisen, seien
    kompatible a_phi : F_phi --> V für alle phi : F --> M gegeben.
    Definiere psi : M --> V durch x |-> a_phi(u), wobei phi : F --> M
    beliebig mit der Eigenschaft phi(u) = x ist. Das ist wohldefiniert.
  * Die Filtriertheit des Diagramms sieht man so.
    Obere Schranke für (A^n --> M) und (A^m --> M) ist (A^{n+m} --> M).
    Ein Möchtegernkokern für

        A ---a---> A^m
         \      /
          \    / x^T
           d  v
             M

    ist (A^m --B^T--> A^r) mit (A^r --n^T--> M), wobei B und n so, dass
    a^T B = 0 und x = B n.

  Das nLab führt folgenden Beweis an: Betrachte die Partialordnung aller
  (Kuratowski-)endlichen Mengen (nicht Familien!) von Elementen in M. Diese ist
  filtriert (d.h. gerichtet) und induziert das Diagramm (X <= M) |-> R<X>.
  Es ist M ein Kolimes dieses Diagramms. Ich sehe aber nicht, wie das klappen
  soll (wie man die universelle Eigenschaft nachweisen soll).

* Sei J endlich erzeugt. Dann sind äquivalent:

  1. A/J ist flach über A.
  2. J = J^2.
  3. J = (e) für ein e aus A mit e^2 = e.

  1 ==> 2 gilt sogar ohne Endlichkeitsvoraussetzung: Die exakte
  Sequenz 0 --> J --> A --> A/J --> 0 bleibt unter Tensorieren mit A/J exakt,
  also erhalten wir 0 --> J/J^2 --> A/J --> A/J --> 0. Die vordere Abbildung
  ist Null. Also J/J^2 = 0.

  2 ==> 3 geht mit Nakayama. J ist als A-Modul endlich erzeugt und es gilt JJ = J.
  Also existiert x mit x = 1 mod J und xJ = 0. Dann J = (1-x), denn für y aus J
  gilt y = y - xy = (1-x) y. Ferner (1-x)^2 = (1-x) - (1-x) x = 1-x.

  3 ==> 1 folgt sofort, da A sich als A/(e) oplus A/(1-e) zerlegt und A flach
  ist.

* Sei phi : A --> B flach. Dann sind äquivalent (Qing Liu,
  http://zll22.user.srcf.net/dpmms/thesis.pdf, Seite 175):

  1. phi ist treuflach.
  2. Spec(phi) ist surjektiv.
  3. Jedes maximale Ideal von A ist Rückzug eines maximalen Ideals von B.
  4. Jeder Basiswechsel von phi ist injektiv.

  Wegen 3. sind insbesondere flache lokale Ringhomos zwischen lokalen Ringen
  stets treuflach.

  Anders: Spec(phi) ist flach und surjektiv genau dann, wenn phi (flach und)
  treuflach ist.

* Untermoduln flacher Moduln sind im Allgemeinen nicht wieder flach
  (außer, der Faktormodul ist es auch). Beispielsweise sind Ideale eines Rings
  im Allgemeinen nicht flach über dem Ring. (Das gilt natürlich nicht für
  Hauptideale, die von einem regulären Element erzeugt werden.)


=== Tensorprodukt

* Tensorieren ist exakt, wenn der rechteste Modul flach ist
  Klar mit Tor.

  http://www.math.lsa.umich.edu/~hochster/615W10/supFlatCoker.pdf

* Die Rechtsexaktheit des Tensorprodukts kann man so zeigen.

  Sei A --> B --> C --> 0 exakt.

  Wir wollen zeigen, dass ker(beta tensor M) <= im(alpha tensor M) =: D.
  Betrachte dazu die kanonische Abbildung (B tensor M)/D --> C tensor M.
  Diese besitzt eine Umkehrabbildung. Daher ist D Teilmenge des Kerns.

* R/(I + J) ~~ R/I tensor_R R/J.

* M tensor_A N ~~ A tensor_{A tensor_k A} (M tensor_k N),
  wenn k ein Körper, A eine k-Algebra und M und N A-Moduln sind.

* k[x] tensor_k k[y] = k[x,y] folgt wie folgt aus abstraktem Nonsens:
  Der Vergissfunktor k-Alg --> Set hat einen Linksadjungierten, nämlich
  X |-> k[X] := k[x | x aus X]. Dieser bewahrt daher Kolimiten.
  Somit ist k[x,y] = k[{x,y}] der Kolimes von k[x] mit k[y]. Nun nutzt man noch
  aus, dass Kolimiten durchs Tensorprodukt gegeben sind.

* Sei A = span(a_1,...,a_m) ein endlich erzeugter R-Modul. Sei B ein beliebiger
  R-Modul. Dann ist ein Tensor der Form sum_i a_i tensor b_i genau dann Null in
  A tensor B, wenn es eine Matrix (r_ij) und einen Vektor (c_j) (mit Einträgen
  aus B) gibt sodass

      b_i = sum_j r_ij c_j  und  sum_i a_i r_ij = 0.

  Symbolisch: b = R c und a^T R = 0.

  Die Rückrichtung ist klar.

  Zur Hinrichtung baue die Surjektion R^m --> A, e_i |-> a_i und betrachte dann
  die wegen Merus Lieblingswitz exakte Sequenz

      ker(R^m --> A) tensor B ---> B^m ---> A tensor B ---> 0.

  Das Element (b_i)_i geht dann auf Null und besitzt daher ein Urbild.

  Die ursprüngliche Quelle dafür ist
  http://archive.numdam.org/item/SAC_1967-1968__2__A2_0, verlinkt von Martin
  Brandenburg bei
  https://mathoverflow.net/questions/86923/elements-in-a-localization-category-theoretic-approach.

* V^ tensor W^ --> (V tensor W)^ ist ein Iso, falls einer der beiden Moduln
  endlich frei ist.

* Sei k ein geometrischer Körper. Genau dann ist eine k-Algebra A
  treuflach über k (flach ist sie automatisch), wenn der Strukturmorphismus k --> A
  injektiv ist, d.h. wenn die Familie (1) linear unabhängig ist, d.h. wenn es
  irgendein Element v in A gibt, sodass die Familie (v) linear unabhängig ist,
  d.h. wenn 1 != 0 in A.

  Seien A und B k-Algebren. Genau dann ist A tensor_k B = 0, wenn A = 0 oder B = 0.
  Die Rückrichtung ist ja klar. Die Hinrichtung geht so: Sei A tensor B = 0.
  Dann ist insbesondere 1 tensor 1 Null in A tensor B. Da A flach ist,
  bleibt die Injektion span_k(1) --> B nach Tensorieren mit A injektiv.
  Somit ist schon 1 tensor 1 aus A tensor span_k(1) Null. Damit gibt es
  Körperlemente r_i und Elemente a_i aus A mit

      1 = sum_i r_i a_i in A  und  r_i = 0 in B.

  Da k ein geometrischer Körper ist, folgt: 1 = 0 in A oder 1 = 0 in B.

  Eine Familie von k-Algebren A_i ist genau dann gemeinsam treuflach, wenn für
  alle endlich präsentierten k-Algebren T gilt:

      Gilt für alle i jeweils T = 0 oder A_i = 0, so ist schon T = 0.

  In klassischer Logik gilt: Eine Familie von k-Algebren ist genau dann
  gemeinsam treuflach, wenn es einen Index gibt, sodass der entsprechende
  Strukturmorphismus injektiv ist.

  Konstruktiv gilt noch: Eine endliche Familie von k-Algebren ist genau dann
  gemeinsam treuflach, wenn nicht alle Algebren der Familie Null sind.


=== Nakayama

* Sei A ein lokaler Ring und M ein endlich erzeugter A-Modul.
  Dann:
      minimale Anzahl von A-Erzeugern von M
    = minimale Anzahl von k-Erzeugern von M/mM.

  Denn:
  1. Sei M durch x_1,...,x_n erzeugt als A-Modul. Dann wird M/mM durch
     [x_1],...,[x_n] als k-Vektorraum erzeugt.
  2. Sei M/mM erzeugt durch [x_1],...,[x_n] als k-Vektorraum.
     Dann wird M nach Nakayama durch x_1,...,x_n als A-Modul erzeugt.

* In http://math.uga.edu/~pete/integral.pdf, Prop. 3.44, steht folgende
  Verallgemeinerung von Nakayama: Sei I ein Ideal in einem Ring A und sei M ein
  endlich erzeugter A-Modul. Dann gilt I + ann(M) = A genau dann, wenn IM = M.

* Sei M endlich erzeugt. Gelte aM = M. Dann gibt es ein normiertes Polynom f
  mit Einträgen aus gewissen Potenzen von a, sodass f(1) M annihiliert. Es gilt
  f(1) = 1 mod a.

  Seien x_1,...,x_n Erzeuger. Schreibe x_i = sum_j a_ij x_j mit a_ij aus a.
  Setze f als das charakteristische Polynom von A. Dann:

      f(1) * [x_1;...;x_n] = det(E-A) [x_1;...;x_n] =
          ad(E-A) (E-A) [x_1;...;x_n] = ad(E-A) * 0 = 0,

  denn [x_1;...;x_n] = A [x_1;...;x_n].

* Aus M_m = 0 für alle maximalen Ideale m folgt bekanntlich M = 0,
  auch, wenn M nicht endlich erzeugt ist.

  Die analoge Behauptung mit den Fasern M(m) = M_m/mM_m statt den Halmen stimmt
  im Allgemeinen nicht. Hinreichend ist, dass M endlich erzeugt ist; denn dann
  folgt aus M(m) = 0 schon M_m = 0. Ein Gegenbeispiel ist durch M = Q und A =
  Z_(p) gegeben. Die Basis A hat genau ein Primideal. Die Faser von M über
  diesem Primideal ist der Nullmodul, M selbst aber ist es nicht.

  Ein anderes Gegenbeispiel ist M = Q/Z und A = Z. Alle Fasern sind Null.

  Aber: Wenn der Grundring noethersch ist und alle derivierten Fasern
  verschwinden, so stimmt es, dass der Modul Null ist!
  https://mathoverflow.net/questions/12992/when-does-a-quasicoherent-sheaf-vanish


=== Invariant Basis Number, Wohldefiniertheit des Rangs

Konstruktiver Beweis für R^n ~~ R^m ==> n = m oder 1 = 0 (R kommutativ):

Fred Richman. Nontrivial uses of trivial rings. 1988.
http://www.ams.org/journals/proc/1988-103-04/S0002-9939-1988-0954974-5/S0002-9939-1988-0954974-5.pdf


=== Matrizen über nichtkommutativen Grundringen

Sei R nicht unbedingt kommutativ.

* R^n (Spaltenvektoren) sollte man als Rechts-R-Modul ansehen.
* R_n (Zeilenvektoren)  sollte man als Links-R-Modul ansehen.

* R^n --> R^m, x |-> Ax ist Rechts-R-linear.
* R_m --> R_n, y |-> yA ist Links-R-linear.

* End(R^n) = R^(n x n), wie gewohnt.
* End(R_n) = R^(n x n, op)!


=== Krulldimension

* Es gilt: dim R/(a) < dim R, falls a regulär; kann das einfach mit der
  konstruktiven Definition von Krulldimension nachweisen.

* Sei 0 --> M' --> M --> M'' --> 0 exakt.

  Dann Ann(M) <= Ann(M') cap Ann(M'') und Ann(M') * Ann(M'') <= Ann(M),
  also sqrt(Ann(M)) = sqrt(Ann(M')) cap sqrt(Ann(M'')).

* dim A/I = dim A/sqrt(I), da allgemein dim A = dim A/sqrt(0).

* Ich erwarte dim(M) <= n genau dann, wenn dim(M') <= n und dim(M'') <= n.

  Das würde aus dim A/(I cap J) <= n genau dann, wenn dim A/I <= n und dim A/J <= n folgen.

  Hintergrund: Unterkategorie der kohärenten Garben mit Kodimension des Trägers >= i
  ist Serresche Unterkategorie (siehe Marco Schlichting, Higher Algebraic
  K-Theory, Seite 211).

* Krull-Dimension 0 impliziert nicht Noetherizität: Betrachte
  R = k[x_1,...]/(x_1, x_2^2, x_3^3, ...). In diesem Ring ist jedes Element
  aus m = (x_1,x_2,...) nilpotent, also hat der Ring Krull-Dimension <= 0.
  Aber m ist nicht endlich erzeugt.
  http://math.stackexchange.com/a/806933/61604

* Noetherizität impliziert nicht endliche Krull-Dimension:
  Es gibt ein Gegenbeispiel von Nagata. :D
  https://mathoverflow.net/questions/21067/noetherian-rings-of-infinite-krull-dimension
  https://math.stackexchange.com/questions/1109732/noetherian-ring-with-infinite-krull-dimension

* A --> B surjektiv, dann dim(B) <= dim(A). Stimmt das? Ja, logo.
  Klar über Primidealketten oder über die konstruktive Definition.

  Es gilt auch eine Art Umkehrung: Sei (A --> B_i)_i eine endliche Familie
  aus surjektiven Ringhomos, die gemeinsam injektiv ist. (Es genügt schon, dass
  Elemente aus dem gemeinsamen Kern nilpotent sind.) Dann ist dim A = sup_i dim B_i.

  Die Endlichkeit ist wichtig: Sonst betrachte (Z --> Z/(p))_p.

  Ich denke, habe aber nicht geprüft, dass es für den endlichen Fall ein
  einfaches konstruktives Argument gibt. (Klassisch nutze aus, dass ein
  Primideal, das einen endlichen Schnitt von Idealen umfasst, schon eines der
  Ideale umfasst.)

* Sei p ein minimales Primideal. Sei I_x = (x) + (sqrt(0):x).
  Dann ist I_x keine Teilmenge von p.

  Denn angenommen doch. Dann liegt x in p. Also (A_p besitzt nur ein Primideal)
  gibt es ein u mit x^n u = 0 und u nicht in p. Es liegt u in (sqrt(0):x).
  Also liegt u doch in p.

  Sei p < q eine echte Inklusion von Primidealen mit x als Zeuge.
  Dann I_x <= q.

  Besserer ("konstruktiverer") Beweis so: Es besitzt A_p nur ein Primideal.
  Also ist jedes Element von A_p invertierbar oder nilpotent. Wir betrachten
  speziell x/1.

  Im ersten Fall folgt, dass x nicht in p liegt. Somit liegt in I_x, aber nicht p.
  Also ist I_x keine Teilmenge von p.

  Im zweiten Fall folgt, dass es ein u gibt, das nicht in p liegt und eine
  Identität der Form u x^n = 0 erfüllt. Somit liegt u in I_x, aber nicht in p.
  Also ist I_x keine Teilmenge von p.

* In http://math.fau.edu/richman/Docs/paperlatex.pdf steht: Ein Ring ist
  genau dann nulldimensional, wenn für alle x das Ideal

      (x) + bigcup_n (0 : x^n)

  das Einsideal ist.

* Sei A ein lokaler Ring. Genau dann ist dim(A/J) <= 0, wenn für alle x aus A
  gilt:

      x ist invertierbar modulo J  oder  x ist nilpotent modulo J.

* Sei A eine Algebra über einem Körper k, welche als k-Vektorraum von Dimension n
  ist. Sei x ein nilpotentes Element in A. Dann könnte man glauben, dass schon
  x^n = 0 ist.

  Das würde (durch Betrachtung des charakteristischen Polynoms) dadurch folgen,
  dass nilpotente Matrizen spurfrei sind.

  Wenn Körper aber nur meint "nicht Null ==> invertierbar", so kann es keinen
  konstruktiven Beweis dieser Aussage geben. Denn im großen Zariski-Topos zum
  Basisschema Spec(k[eps]/(eps^2)) ist die 1x1-Matrix (eps) nilpotent. Trotzdem
  gilt in dem Topos nicht, dass eps^1 = 0.


=== Weil-Algebren

* Kock definiert eine Weil-Algebra über k als eine k-Algebra, die von der
  Form k^n ist, wobei (1,0,...0) die Eins angibt und die Menge I := { (0,*,...,*) }
  ein Ideal mit I^n = 0 ist. (Für mich ist nicht klar, ob man auch I^m = 0 für
  ein m >= 0 fordern kann.)

* Eine basisfreie Definition ist folgende: Eine k-Algebra A ist genau dann
  eine Weil-Algebra, wenn es einen k-Algebren-Homo pi : A --> k und eine Zahl n
  gibt, sodass A als k-Vektorraum frei vom Rang n ist und ker(pi)^n = 0 ist.

* Eine Weil-Algebra lässt sich stets über die Darstellungsmatrix der bilinearen
  Multiplikationsabbildung beschreiben, also durch eine (n x n^2)-Matrix.
  Die Bedingung, dass I^n = 0 sein muss, ist dann lediglich eine Ansammlung von
  Gleichungsbedingungen an die Koeffizienten dieser Matrix.

* Weil-Algebren sind als k-Algebren damit stets endlich präsentiert:

      k[X_1,...,X_n]/(X_1 - 1, X_i X_j - sum_k gamma_ijk X_k),

  wenn e_i e_j = sum_k gamma_ijk e_k in A.

  Habe nämlich einen kanonischen Homo von dieser Algebra in A hinein
  (schicke X_i auf e_i), welcher offensichtlich surjektiv ist (Urbild von e_i
  ist X_i) und auch injektiv ist. Nutze dazu, dass jedes Element in dieser
  Polynomalgebra durch ein homogenes Polynom vom Grad 1 dargestellt werden
  kann.

* Aber nicht alle endlich präsentierten und als k-Vektorraum
  endlich dimensionalen Algebren sind Weil-Algebren. Etwa ist k x k
  es wohl nicht.


=== Reguläre Ringe

* http://www2.math.uu.se/~palmgren/symposium_constructivity_computability/Coquand.pdf,
  Folie 11

* Ein Ring heißt dort genau dann regulär, wenn jedes endlich erzeugte Ideal
  eine endliche freie Auflösung besitzt.

* Idee: Lokale Ringe an glatte Punkte algebraischer Varietäten sind regulär.

* R noethersch und regulär ==> R UFD.
* R regulär ==> R hat ggT's.

* Coquand zeigt, wie man aus einer Präsentation eines Ideals der Form

      0 --> R^n --> R^(n+1) --> (a_0,...,a_n) --> 0

  folgern kann, dass die a_i einen ggT haben, welcher zudem regulär ist.

* Eine endliche freie Auflösung eines Ideals I definiert eine
  Euler-Charakteristik als alternierende Summe der Ränge.

  Laut Coquand besagt Vasconcellos Theorem, dass:
  chi = 0 ==> I = 0.
  chi = 1 ==> I ist regulär.
  sonst   ==> 1 = 0 in R.

* Coquand, Quitté. Constructive finite free resolutions.
  http://link.springer.com/article/10.1007%2Fs00229-011-0466-5


=== Freie Moduln

* Ist R ein Integritätsbereich in dem jedes Ideal ein Hauptideal ist,
  so sind Untermoduln endlich freier Moduln über R wieder endlich frei.
  (klassisch, vielleicht auch bei geeigneter Formulierung konstruktiv)

  Beweis steht in D. Northcott, Finite Free Resolutions, Seite 96.

* Klassisch gilt: Endlich erzeugte freie Moduln sind "endlich frei",
  also von der Form A^n.

  Konstruktiv gilt nur: Ist ein Modul frei über eine Menge I und endlich
  erzeugt, so ist I kuratowskiendlich. Eine Aufzählung der Elemente von I
  erhält man nämlich, indem man die vorkommenden Basiselemente der gegebenen
  Erzeuger zusammensetzt. Zum Nachweis, dass das alle sind, benötigt man
  unten stehendes Lemma.

  Man kann aber noch etwas mehr zeigen: Wenn der Modul ein Erzeugendensystem
  der Länge n besitzt, so besitzt I auch eine Aufzählung der Länge höchstens n
  (falls 1 != 0 im Ring). Das geht so: Drücke die Erzeuger (v_1,...,v_m) über
  die Basisvektoren (aufgezählt durch (e_1,...,e_n)) und umgekehrt aus.
  Das führt zu zwei Matrizen A und B:

      e_i = sum_j A_ji v_j
      v_j = sum_i B_ij e_i

  Wenn man die zweite Gleichung in die erste einsetzt, erhält man

      e_i = sum_l (BA)_li e_l.

  Die kann man nun sukzessive mit unten stehendem Lemma bearbeiten. So erhält
  man in jedem Schritt entweder die Information, dass zwei Basisvektoren der
  Aufzählung schon gleich sind, in welchem Fall man dann induktiv von vorne
  beginnt, oder dass der entsprechende Eintrag von BA gleich delta_li ist.

  Wenn man damit fertig ist, folgt also BA = 1. Somit ist B surjektiv.
  Da B m Spalten und n Zeilen hat, und 1 != 0 vorausgesetzt ist, folgt m >= n.

  Bonusaussage: Wenn der Modul kein Erzeugendensystem der Länge <= m-1 besitzt,
  und weiterhin 1 != 0 ist, so ist die Menge I schon endlich. Denn in der
  gekürzten Aufzählung sind Elemente mit unterschiedlichem Index auch
  verschieden.

  Bonusaussage: In A<X> mit X = { x_1, ..., x_n } (der Fall A = 0 ist zugelassen)
  ist die Familie (x_1,...,x_n) linear unabhängig in folgendem Sinn:

      Ist sum_i a_i x_i = 0, so sind alle a_i = 0 oder es gibt i != j mit x_i = x_j.

  Mit dieser Bonusaussage kann man zeigen: Ist A<X> endlich präsentiert, so ist X
  endlich und A<X> endlich frei.

  Genau dann ist ein A-Modul frei (auf irgendeiner Menge), wenn es eine Familie
  von Vektoren gibt (durch irgendeine Menge indiziert), sodass jeder Vektor
  Linearkombination von Vektoren aus der Familie ist und sodass jede endliche
  Aufzählung von Vektoren aus der Familie linear unabhängig in dem
  allgemeineren Sinn ist.

* Genau dann sind in einem freien Modul zwei Linearkombinationen
  sum_i a_i e_i und sum_j b_j e'_j gleich, wenn:

  Für alle x aus der Basismenge und
  für alle K <= {1, ..., n} und J <= {1, ..., m}
  sodass alle e_i und e'_j mit i aus K und j aus J jeweils gleich x sind
  gibt es Obermengen K' und J' mit derselben Eigenschaft
  sodass sum_{i in K'} a_i = sum_{j in J'} b_j.

  Eine analoge Charakterisierung gilt für direkte Summen von Moduln
  (freie Moduln sind ja der Spezialfall für direkte Summen des Grundrings).

  Man zeigt die Charakterisierung so:
  1. Die angegebene Bedingung definiert eine Äquivalenzrelation.
  2. Die so definierte Äquivalenzrelation macht die kleinen Schritte
     (Umordnung der formalen Summanden, Entfernen von Summanden mit Koeffizient
     Null, Kontraktion von Summanden zum selben Basiselement) mit.
  3. Sie ist die kleinste Äquivalenzrelation, die die kleinen Schritte
     mitmacht. Dazu Induktion und Ausnutzung, dass Addition in Moduln
     cancellative ist.

  Bessere Charakterisierung wird in
  https://mathoverflow.net/questions/302516/constructively-is-the-unit-of-the-free-abelian-group-monad-on-sets-injective
  diskutiert. Sie funktioniert auch für Rigs.

  Tatsächlich stimmt die "bessere Charakterisierung" mit der hier gegebenen
  überein. Also geht auch diese hier für Rigs. Habe mich beim Beweis von
  Schritt 3 nur doof angestellt (zu früh Induktion verwendet).


=== Purity filtration

* eps : M --> M^^ weder injektiv noch surjektiv, im Allgemeinen.

* coim(eps) ist der letzte Teil einer aufsteigenden Filtration von M.

* Sei t_{-c}(M) der größte Untermodul von Kodimension >= c. Dann heißt

    ... <= t_{-2}(M) <= t_{-1}(M) <= t_0(M) = M

  die purity filtration von M.

* Es gilt: t_{-1}(M) = ker(eps).

* Die anderen Schritte kann man erhalten, wann die Abbildung von M
  in den doppelt deriviert-dualen Modul betrachtet.
  http://homalg.math.rwth-aachen.de/~barakat/talks/purity.pdf


=== Vervollständigung

* http://www.northeastern.edu/castravet/MATH840/hmw7.pdf
  k[[x,y]]/(f_r + f_{r+1} + ... + f_d) ~~ k[[x]] genau dann, wenn r = 1.
  (Dabei deg f_n = n.)

* Lokalisieren an S = 1 + m ist dasselbe wie Lokalisieren an T = A \ m,
  wenn m ein maximales Ideal ist. Denn S <= T und T <= Sat(S).

* Die m-adische Vervollständigung ist lokal, wenn m ein maximales Ideal ist.

  Allgemeiner: Die a-adische Vervollständigung eines Rings ist genau dann
  lokal, wenn A/a lokal ist.
  http://math.stackexchange.com/questions/263468/completion-of-a-polynomial-ring-w-r-t-a-maximal-ideal

* Die m-adische Vervollständigung von C^infty(R), wobei m = { f | f(0) = 0 },
  ist der formale Potenzreihenring R[[X]]. Zum Beweis benötigt man nur
  Hadamards Lemma.

* Z^, der Prüferring: lim_n Z/(n) (bezüglich der Teilbarkeitsordnung).

  Alternativ lim_n Z/(n!), diesmal mit der gewöhnlichen Ordnung.

  Das führt zum faktoriellen Ziffernsystem.
  http://arxiv.org/pdf/1304.6532v1.pdf, Seite 13


=== Nichtkommutative Besonderheiten

Wenn man "M tensor_A N" schreibt, so muss M ein Rechts-A-Modul und N ein
Links-A-Modul sein. Das Ergebnis ist dann kein A-Modul mehr, nur noch
eine abelsche Gruppe. Die fundamentale Rechenregel fürs Tensorprodukt
ist xa tensor y = x tensor ay für a aus A, x aus M und y aus N.

Das Tensorprodukt frisst also die Skalarwirkung auf, über die tensoriert
wird. Nur wenn die Faktoren noch zusätzliche Modulstrukturen auf anderen
Seiten hat, überlebt eine Skalarmultiplikation das Tensorieren:

Wenn M sogar ein B-A-Bimodul ist (also Links-B-Modul und Rechts-A-Modul
auf kompatible Art und Weise), so wird M tensor_A N zu einem
Links-B-Modul.

Wenn analog N A-C-Bimodul ist, so wird M tensor_A N zu einem
Rechts-C-Modul.

Zu guter Letzt: Wenn M sogar ein B-A-Bimodul und N ein A-C-Bimodul ist,
so wird M tensor_A N zu einem B-C-Bimodul.

Die universelle Eigenschaft betrifft bilineare Abbildungen f : M x N --> P
in beliebige abelsche Gruppen P, wobei die Bilinearität meint:

1. f(x+x',y) = f(x,y) + f(x',y)
2. f(x,y+y') = f(x,y) + f(x,y')
3. f(xa,y) = f(x,ay)

Beim Hom ist es übrigens ähnlich. "Hom_A(M, N)" kann man nur dann
schreiben, wenn M und N entweder beides Rechts-A-Moduln oder beides
Links-A-Moduln sind. Das Ergebnis ist kein A-Modul mehr, nur noch eine
abelsche Gruppe. Nur falls M und N sogar Bimoduln sind, ist die
Hom-Menge wieder ein Modul.

* Hom_A(B-A-Bimodul, Rechts-A-Modul) ist ein Rechts-B-Modul.
* Hom_A(A-B-Bimodul, Links -A-Modul) ist ein Links-B-Modul.
* Hom_A(Links-A-Modul,  A-B-Bimodul) ist ein Rechts-B-Modul.
* Hom_A(Rechts-A-Modul, B-A-Bimodul) ist ein Links-B-Modul.


=== Primärzerlegung

* Sei a = q_1 cap ... cap q_n eine minimale Primärzerlegung.

  Dann umfasst jedes Primideal, das a umfasst, schon eines der sqrt(q_i).

  Die isolierten Primideale haben sogar die Eigenschaft, Primideale zu sein,
  die minimal über a sitzen.

  Denn: Sei a <= p <= sqrt(q_j). Dann gibt es i mit sqrt(q_i) <= p <= sqrt(q_j).
  Da sqrt(q_j) isoliert ist, folgt sqrt(q_i) = p = sqrt(q_j).

* Sei p ein Primideal, das minimal mit der Eigenschaft ist, ein gegebenes
  zerlegbares Ideal a zu umfassen. Dass ist p ein isoliertes Primideal zu a.

  Denn: Schreibe a wie oben. Zunächst erhält man, dass p eines der sqrt(q_i)
  umfasst. Da sqrt(q_i) ein Primideal über a ist, folgt p = sqrt(q_i). Damit
  ist q zu a assoziiert. Ist nun p' irgendein assoziiertes Primideal zu a
  mit p >= p', so folgt wieder wegen der Minimalität p = p'. Also ist p sogar
  isoliert.

* Ein Ideal, das nicht primär ist, aber die abgeschwächte Definition

      1 \not\in q und
      xy in q ==> x in sqrt(q) oder y in sqrt(q)

  erfüllt, ist q := (x^2, xy) in K[x,y]. Es ist nicht primär, denn das Element xy
  liegt in q, aber x liegt nicht in q und y liegt nicht in sqrt(q). Es erfüllt
  aber die schwächere Definition. Denn ist fg ein Element von q, so ist fg ein
  Vielfaches von x, also ist f ein Vielfaches von x oder g; im ersten Fall ist
  f^2 in q, im zweiten g^2.


=== Satz von Artin--Schreier

http://www.math.uconn.edu/~kconrad/blurbs/galoistheory/artinschreier.pdf

Besitze ein Körper F einen algebraischen Abschluss C, der endlich über F ist.
Dann "verhält sich F wie die reellen Zahlen". Insbesondere ist char F = 0 und
C = F(i).


=== Morita-Äquivalenz

* R ist Morita-äquivalent zu R^{n x n}.

  Ist M ein R-Modul, so ist M^n ein R^{n x n}-Modul.

  Ist N ein R^{n x n}-Modul, so ist { es | s in N } ein R-Modul,
  wobei e die (n x n)-Matrix mit einer 1 oben links und sonst Nullen
  bezeichnet.

  Details: http://planetmath.org/moritaequivalence

* R^{n x n} ist "nicht ernsthaft" nichtkommutativ.


=== Siehe auch

* http://math.uga.edu/~pete/integral.pdf
