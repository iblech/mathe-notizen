=== Obere Schranken für Gegenbeispiele und Beweise

Gustavo Lacerda.
Upper-Bounding Proof Length with the Busy Beaver.
http://arxiv.org/abs/1406.1808

Sehr einfach zu verstehen!


=== Busy Beaver besiegt jede berechenbare Funktion

Sei f eine berechenbare Funktion.

* Sei M_n eine Turingmaschine, die wie folgt arbeitet: n Einsen schreiben, dann
  wieder nach vorne gehen, dann die Maschine für f ausführen, dann wieder nach
  vorne, dann noch mal f, dann wieder nach vorne und einmal ablaufen.

  Die Maschine M_n benötigt mindestens f(f(n)) Schritte und hat

      n + a + |f| + a + |f| + a + b =: 2|f| + c + n

  Zustände. Dabei sei a die Anzahl Zustände, die nötig sind, um nach vorne zu
  spulen, und b die Anzahl Zustände, die nötig sind, um bis ans Ende zu spulen.

  Folglich: f(f(n)) <= BB(2|f| + c + n).

  Schön wäre jetzt: f(2|f| + c + n) <= f(f(n)), zumindest ab irgendeinem n.

  Das können wir arrangieren: Hinreichend dafür ist, dass f schwach monoton
  steigt und f(n) >= 2|f| + c + n gilt.

  Einfachste Möglichkeit: Wir ersetzen f durch F mit

      F(n) = max { f(0), ..., f(n) } + 2n.

  Dann haben wir:

      f(2|F| + c + n) <= F(2|F| + c + n) <= F(F(n)) <= BB(2|F| + c + n)
            für n >= 2|F| + c

* Alternativ: M_n schreibt n Einsen, spult nach vorne, verdoppelt die Anzahl
  Einsen, führt die Maschine für f aus, spult nach vorne, läuft die Einser ab.
  Dann braucht M_n mindestens f(2n) Schritte und hat

      n + a + d + |f| + a + b =: |f| + e + n

  Zustände. Folglich f(2n) <= BB(|f| + e + n). Wenn f schwach monoton ist, gilt

      f(|f| + e + n) <= f(2n) <= BB(|f| + e + n)
            für n >= |f| + e.

* Wenn f nicht unbedingt schwach monoton ist, und wir f aus didaktischen Gründen
  nicht ersetzen möchten, so können wir wie folgt vorgehen.

  Sei M_n folgende Maschine: n Einsen schreiben, mittels der Maschine für f
  die Werte f(0), f(1), ..., f(2n) berechnen und jeweils die entstehenden Einsen
  komplett ablaufen.

  Dann führt M_n mindestens max { f(0), ..., f(2n) } Schritte aus und hat k + n
  Zustände, wobei k eine gewisse Konstante ist, die von der Maschine für f
  abhängt.

  Somit:

      f(k + n) <= max { f(0), ..., f(2n) } <= BB(k + n)
          für n >= k.


=== Turings ursprüngliche Definition berechenbarer reeller Zahlen

http://jdh.hamkins.org/alan-turing-on-computable-numbers/

Turings Definition war: Eine Zahl ist genau dann berechenbar, wenn es eine
Turingmaschine gibt, die mehr und mehr Zehnerziffern ausgibt.

Die moderne Definition ist natürlich: Eine Zahl ist genau dann berechenbar,
wenn eine Turingmaschine gibt, die bessere und bessere rationale
Approximationen berechnet.

Es ist klar, dass jede in Turings Sinn berechenbare Zahl auch im modernen Sinn
berechenbar ist. Die Umkehrung stimmt ebenfalls, klassische Logik
vorausgesetzt, denn eine Turings Sinn berechenbare Zahl ist entweder rational
(in welchem Fall es leicht ist, eine Maschine anzugeben, die rationale
Approximationen bestimmt) oder irrational (in welchem Fall es kein Problem mit
"0.999... vs. 1.000..." gibt).

Aber Turings Definition leitet zur falschen Definition von Berechenbarkeit von
Funktionen. Addition auf Repräsentanten in Turings Sinn ist nicht berechenbar.


=== Notions of computability at higher types

http://cstheory.stackexchange.com/questions/1117/realizability-theory-difference-in-power-between-lambda-calculus-and-turing-mac
http://homepages.inf.ed.ac.uk/jrl/Research/notions1.pdf


=== Berechenbarkeit im Grenzwert (computability in the limit)

Eine Funktion N --> N ist genau dann im Grenzwert berechenbar, wenn sie es durch
eine Turingmaschine mit Zugriff auf ein Halteorakel ist.
https://mathoverflow.net/a/277515/31233


=== Der Kleene-Baum

* Es gibt eine berechenbare partielle Funktion d : N --` {0,1} sodass für
  jede berechenbare totale Funktion f : N --> N eine natürliche Zahl n
  existiert, sodass d(n) definiert ist und ungleich f(n) ist.

  Dazu definiere d(n) so: Simuliere die n-te Turingmaschine mit Eingabe n.
  Falls das nicht terminiert, ist der Wert von d(n) undefiniert. Ansonsten ist
  er 0, falls das Ergebnis nicht 0 war, und 1 sonst.

  Ist nun eine berechenbare totale Funktion f gegeben, so gibt es ein n,
  sodass f durch die n-te Turingmaschine realisiert wird. Folglich ist d(n)
  definiert und ungleich f(n).

* Ein Wort a in 2^* liegt genau dann im Kleene-Baum, wenn a "die Folge d
  sein könnte". Damit ist folgendes gemeint.

  Fixiere eine Maschine D, die d berechnet, etwa die oben skizzierte.
  Ein Wort a der Länge l liegt genau dann im Kleene-Baum, wenn für
  alle 1 <= i <= l, für die D(i) nach höchstens l Schritten terminiert hat,
  gilt, dass der i-te Buchstabe von a gleich d(i) ist.

* Der Kleene-Baum enthält (berechenbar) unendlich viele Elemente.

  Denn sei n eine beliebige Zahl. Dann definieren wir die Buchstabenfolge
  a_1...a_n durch

      a_k := d(k), falls D(k) nach <= n Schritten gehalten hat;
             0,    sonst.

* Nach Königs Lemma enthält der Kleene-Baum daher einen unendlichen Pfad.
  Aber er enthält keinen berechenbaren unendlichen Pfad.

  Denn sei ein beliebiger berechenbarer Pfad in 2^* gegeben. Dann können wir
  eine totale berechenbare Funktion f : N --> {0,1} durch f(n) := der n-te
  Buchstabe des n-ten Worts auf dem Pfad definieren. Dank der Magie von d
  gibt es eine natürliche Zahl n für die d(n) definiert und ungleich f(n) ist.
  Sei m die Anzahl Schritte, die D(n) bis zur Terminierung benötigt. Ohne
  Einschränkung m >= n. Dann liegt das m-te Wort des Pfads nicht im Kleene-Baum.

* Andrej erklärt das in Realizability for the Physical World so: "To understand how
  strange such a tree is, contemplate the following situation. A master machine
  has built a system of underground tunnels, beginning with a hole at the
  surface. The tunnels always go down, they may split into two, or lead to dead
  ends. We are told that there is no limit to the depth of the tunnels. Yet,
  even if the master machine is known to us we cannot build a machine that
  would enter the hole and always go down without ever hitting a dead end."

* Der Kleene-Baum liefert eine Funktion psi : 2^N --> N (das Exponential soll nur
  die berechenbaren Funktionen enthalten), die nicht gleichmäßig stetig ist:
  Bilde f ab auf die kleinste natürliche Zahl n, sodass das Wort
  [f(0),...,f(n-1)] nicht im Kleene-Baum liegt.

  Stetig ist diese Funktion aber schon: Sei eine Funktion f mit psi(f) = n
  gegeben. Dann gilt psi(f) = psi(g) für alle berechenbaren Funktionen g
  mit f = g auf { 0, ..., n - 1 }.

  Zudem ist diese Funktion nicht beschränkt.

  https://books.google.de/books?id=j6f9CAAAQBAJ&pg=PA70&lpg=PA70
  (Beeson, Foundations of Constructive Mathematics: Metamathematical Studies)

* In PCF ist eine Funktion

      max :: (2^N --> N) --> N

  definierbar. Aber im Modell mit Turingmaschinen (welche im Falle von
  Funktionen höherer Ordnungen passende Kodierungen von sie berechnenden
  Turingmaschinen als Argumente nehmen) funktioniert die Funktion nicht:
  Wegen der nicht beschränkten Funktion aus dem Kleene-Baum.

  Wenn man das Modell so ändert, dass Funktionen durch ihren Graph übergeben
  werden, funktioniert sie wieder. Angeblich, ist mir noch nicht ganz klar.
  Zumindest nicht im Realisierbarkeitsmodell. Hm.

* Sei s : X --> Y eine Surjektion. Existiere eine Funktion

      all : 2^X --> 2

  mit all(p) genau dann, wenn p(x) für alle x in X. Dann gibt es auch die
  analoge Funktion für Y.

* Existiere der Kleene-Baum T. Dann gibt es eine Surjektion 2^N --> N,
  nämlich diejenige Abbildung, die einem unendlichen Pfad die Blattnummer des
  letzten in T befindlichen Knotens des Pfads zuordnet.

  Es gibt auch eine passende rechtsinverse Injektion: Die ordnet einer Zahl n
  einen Pfad zu, der zum n-ten Blatt läuft (und dann immer links abbiegt).

  Ferner ist 2^N isomorph (als metrische Räume, vermöge einer stetigen
  Bijektion mit stetiger Inversem) zu N^N.

* Angenommen, es gibt "all" für X = 2^N. Existiere weiterhin der Kleene-Baum.
  Dann gibt es "all" auch für Y = N. Das ist aber falsch, weil damit das
  Halteproblem lösbar ist.

* Es gibt noch eine Variante des Kleene-Baums von Lacombe, in dem
  die Menge der unendlichen Pfade Maß > 1/2 hat. Siehe Thm. 9.1.17 in
  /Higher-Order Computability/ von Longley und Normann.


=== Modelle von Berechenbarkeit

* Sequentially realizable functions, thematisiert von John Longley in /When is
  a functional program not a functional program?/. Sind in unpurem ML
  implementierbar und funktional, aber nicht in purem ML oder PCF
  implementierbar, da nicht monoton.


=== Noethers Theorem aus "Theorems for free"

http://lambda-the-ultimate.org/node/5078

Robert Atkey
Conservation laws for free!

Invariance is of paramount importance in programming languages and in
physics. In programming languages, John Reynolds’ theory of relational
parametricity demonstrates that parametric polymorphic programs are
invariant under change of data representation, a property that yields
“free” theorems about programs just from their types. In physics, Emmy
Noether showed that if the action of a physical system is invariant
under change of coordinates, then the physical system has a conserved
quantity: a quantity that remains constant for all time. Knowledge of
conserved quantities can reveal deep properties of physical systems. For
example, the conservation of energy, which by Noether’s theorem is a
consequence of a system’s invariance under time-shifting.

In this paper, we link Reynolds’ relational parametricity with Noether’s
theorem for deriving conserved quantities. We propose an extension of
System Fω with new kinds, types and term constants for writing programs
that describe classical mechanical systems in terms of their
Lagrangians. We show, by constructing a relationally parametric model of
our extension of Fω, that relational parametricity is enough to satisfy
the hypotheses of Noether’s theorem, and so to derive conserved
quantities for free, directly from the polymorphic types of Lagrangians
expressed in our system.


=== Fixpunktsatz von Knaster--Tarski

* Sei X ein vollständiger Verband. Sei f : X --> X ein monotoner Operator.
  Dann besitzt f einen größten Fixpunkt, und diesen kann man konstruieren als

      u := sup M  mit  M := { v | v <= f(v) }.

  Zunächst ist klar, dass u existiert.
  Ferner M <= f(u), denn für v in M (also v <= u) gilt v <= f(v) <= f(u).
  Also auch u <= f(u). Somit u in M.
  Dann auch f(u) in M. Also f(u) <= u.
  Also ist u ein Fixpunkt.

  Ferner ist u der größte Fixpunkt. Sei v irgendein Fixpunkt von f.
  Dann v in M. Also v <= u.

  Daran sieht man auch: Ein größtes v mit der Eigenschaft v <= f(v)
  ist ein Fixpunkt (und zwar der größte).

  Die reellen Zahlen bilden zwar keinen vollständigen Verband, doch trotzdem
  gilt: Ist f : R --> R eine (schwach) monoton steigende Abbildung, existiert
  ein v mit v <= f(v) und ist die Menge { v | v <= f(v) } nach oben beschränkt,
  so besitzt f einen größten Fixpunkt. Das stimmt konstruktiv, wenn die
  MacNeille-Zahlen gemeint sind.

* Den kleinsten Fixpunkt bekommt man so:

      u := inf M  mit  M := { v | f(v) <= v }.

  Zunächst ist klar, dass u existiert.
  Ferner f(u) <= M, denn für v in M (also v >= u) gilt f(u) <= f(v) <= v.
  Also auch f(u) <= u. Somit u in M.
  Dann auch f(u) in M. Also f(u) >= u.
  Also ist u ein Fixpunkt.

  Ferner ist u der kleinste Fixpunkt. Sei v irgendein Fixpunkt von f.
  Dann v in M. Also u <= v.

* Und hier noch eine Konstruktionsmöglichkeit für den kleinsten Fixpunkt,
  wenn f Suprema von aufsteigenden Folgen bewahrt:

      u := sup M  mit  M := { bot, f(bot), f^2(bot), ... }.

  Dann f(u) =Vor= sup { f(bot), f^2(bot), ... } = sup M = u.

  Ferner ist u kleinster Fixpunkt, denn ist v irgendein Fixpunkt, so zeigt man
  durch Induktion, dass M <= v. Also auch u <= v.

* Sei X ein vollständiger Verband. Sei f : X --> X ein monotoner Operator.
  Dann gilt für alle y in X:

      (forall x. x <= y ==> f(x) <= y)  ===>  mu(f) <= y.

  Beweis: Betrachte die Teilmenge T := { z | z <= y }.
  T wird mit den gleichen binären Joins und Meets zu einem vollständigen Verband.
  (Achtung, aufpassen bei beliebigen Meets.)
  Nach Voraussetzung wird T von f bewahrt.
  Also existiert ein Fixpunkt mu(f|_T). Damit:

      mu(f) <= mu(f|_T) <= y.

  Im Nachhinein sieht man: Da mu(f) auch in T liegt, gilt sogar mu(f) = mu(f|_T).

* Habe X sogar eine Implikation (rechtsadjungiert zur Meetbildung).
  Dann gilt:

      (forall x. a wedge x <= y ==> a wedge f(x) <= y)  ===>  a wedge mu(f) <= y.

* Analoge Prinzipien gelten auch, wenn man mu(f)_{>= u} meint, den kleinsten
  Fixpunkt oberhalb eines Elements u mit u <= f(u).

      u <= y  und  (forall x. u <= x <= y ==> f(x) <= y)  ===>  mu(f)_{>= u} <= y.

      (forall x. u <= x, a wedge x <= y ==> a wedge f(x) <= y)  ===>  a wedge mu(f)_{>= u} <= y.
      (XXX: auch hier u <= y noch vorauszusetzen?)

* Sei phi : X --> Y ein monotoner Operator, der Suprema erhält.

  Dann gibt es ein phi_* : Y --> X mit

      x <= phi_*(y)  <==>  phi(x) <= y,

  nämlich

      phi_*(y) := sup { x' | phi(x') <= y }.

  Dann gilt für alle y in Y:

      (forall x. phi(x) <= y ==> phi(f(x)) <= y)  ===>  phi(mu(f)) <= y.

  Und für alle y in Y und u mit u <= f(u) gilt:

      (forall x. (u <= x und (phi(x) <= y)) ==> phi(f(x)) <= y)  ===>  phi(mu_{>= u}(f)) <= y.

* Ein Spezialfall: Sei P(x) eine Aussagefamilie über x in X.
  Gelte P(x) ==> P(x') für x <= x' und P(sup_i x_i) <==> bigvee_i P(x_i).
  (Die Monotonie folgt schon aus der Supremumsbewahrung.) Dann:

      (forall x. (u <= x und P(x) ==> Q) ==> (P(f(x)) ==> Q))  ===>
          (P(mu_{>= u}(f)) ==> Q).

* Bessere Prinzipien für den größten Fixpunkt: POPL'13, The power of parameterization in
  coinductive proof. http://plv.mpi-sws.org/paco/


=== Rekursionssatz

* Sei f : N --> N berechenbar. Dann gibt es n mit ev_n ~ ev_{f(n)}.

  Dabei meint p ~ q, dass die Programme p und q dasselbe Verhalten zeigen: Bei
  jeder Eingabe x folgt aus der Terminierung von p(x), dass auch q(x)
  terminiert und zwar mit demselben Ergebnis, und umgekehrt.

  Slogan: Jede berechenbare Quelltextmanipulation hat einen semantischen
  Fixpunkt.

  Der Beweis geht so. Wir definieren zunächst eine berechenbare Funktion h : N -> N
  durch h(x) = Index des Programms "berechne bei eine Eingabe von y zunächst
  e := ev_x(x) und gib dann ev_e(y) zurück".

  Sei nun e = Index des Programms (f . h). Dann ev_{h(e)} ~ ev_{ev_e(e)} = ev_{F(h(e))}.
  Wir sind also fertig mit n := h(e).


=== Komplexität der Schrödinger-Gleichung

http://arxiv.org/abs/1403.7686


=== Morphismenzoo

* Catamorphismus: eindeutiger Morphismus aus einer initialen Algebra heraus.
  mu(F) --> A

* Anamorphismus: eindeutiger Morphismus in eine finale Koalgebra hinein.
  A --> mu(F)

* Sei psi : A --> FA eine Koalgebra und phi : FB --> B eine Algebra. Dann
  ist hylo(phi, psi) = cata(phi) . ana(psi) : A --> B.

* Dann gibt es Histomorphismen und als aufgepimpte Version Dynamorphismen.
  Mit letzteren fängt man das Muster der dynamischen Programmierung ein.
  http://kodu.ut.ee/~eugene/jkmpc06.pdf


=== Minimalzahl Erzeuger und Relationen über homologische Methoden

Philippe Malbos, Samuel Mimram.
Homological Computations for Term Rewriting Systems.
http://math.univ-lyon1.fr/homes-www/malbos/Art/hcTRS.pdf


=== Durchbruch in der Erzeugung von Zufallszahlen

http://eccc.hpi-web.de/report/2015/119/


=== Kein Durchbruch in der Erzeugung von Zufallszahlen, aber trotzdem cool

http://web.eecs.umich.edu/~qstout/abs/AnnProb84.html

Suppose you have a coin and want to flip it to generate a random bit. However,
it may not be a fair coin, i.e., it may be that "heads" and "tails" are not
equally likely. How can you use this potentially biased coin to generate an
unbiased result? In particular, how can you do this when you don't know what,
if any, the coin's bias is?

Von Neumann gave a simple solution: flip the coin twice. If it comes up heads
followed by tails, then call the outcome HEAD. If it comes up tails followed by
heads, then call the outcome TAIL. Otherwise (i.e., two heads or two tails
occured) repeat the process. Throughout we assume that the flips are
independent, and in this case it is easy to show that von Neumann's procedure
simulates an unbiased coin, in that one is exactly as likely to get a HEAD
outcome as a TAIL outcome, no matter what the coin's bias is. Further, no
matter what the bias is (as long as it is not 0 nor 1), in finite expected time
an unbiased outcome will be achieved.


=== Makros, die besser komponierbar sind

http://okmij.org/ftp/Scheme/macros.html#ck-macros


=== Besondere Rolle der in Polynomialzeit berechenbaren Funktionen

* http://www.scottaaronson.com/papers/philos.pdf, Seite 19f.

* Eine Funktion f : N --> N liegt genau dann in FP, wenn f von einem
  Programm berechnet werden kann, dessen Korrektheit in Logik zweiter Ordnung
  (mit Komprehension auf positive quantorenfreie Formeln beschränkt) bewiesen
  werden kann.

* "Results like these provide further evidence—if any was needed—that
  polynomial-time computability is an extremely natural notion: a “wide target
  in conceptual space” that one hits even while aiming in purely logical
  directions."

* "Theorem (Girard '98): there is a consistent refinement of the sequent
  calculus with unrestricted comprehension but restricted contraction in which
  the provably total functions are precisely the polynomial time functions."

  http://therisingsea.org/notes/talk-twothings.pdf


=== Verbindungen zwischen Berechenbarkeit und Logik

* Die Sigma_1-Mengen natürlicher Zahlen sind genau die rekursiv aufzählbaren.
  Und auch genau die Mengen der n's, sodass eine diophantische Gleichung
  f(n, x_1,...,x_m) = 0 lösbar ist.


=== Unmöglichkeit

* If a language can interpret itself then it is not total.
  http://cstheory.stackexchange.com/a/24994/32151
  (Wurde aber etwas relativiert.)


=== Turing-Grade

https://en.wikipedia.org/wiki/Turing_degree

Turinggrade messen, wie schwer genau unschaffbar schwere Probleme sind.

* Ein Problem ist genau dann lösbar, wenn es Turinggrad 0 hat.
  Es ist genau dann äquivalent zum Halteproblem, wenn es Turinggrad 0' hat.

* Es gibt 2^{aleph_0} viele verschiedene Turinggrade. Es gibt mindestens
  eine Menge von Turinggraden derselben Größe, deren Elemente paarweise
  unvergleichbar sind.

* Es gibt minimale Grade über 0. Der Grad 0' ist aber nicht minimal.
  (Sozusagen ist die Kontinuumshypothese für Turinggrade falsch.)

* Jede abzählbare Partialordnung lässt sich in Ordnung der Turinggrade
  einbetten.


=== Monotone Setzungen (Idee von Marc)

* Wie stark ist konstruktive Logik, wenn wir sie um den epsilon-Operator
  ergänzen? Wenn wir ihn auch bei Funktionsdefinitionen erlauben, kann
  man offensichtlich das Auswahlaxiom folgern.

* Kann man mit monotonen Setzungen schon einen sinnvollen Term

        lem :: Either a (a -> r)

  angeben? (Vermutung: Nein.)

Tim: Marc, Matthias und ich haben vorhin über eine mögliche
Spracherweiterung von Haskell diskutiert: Monotone Setzungen. Anders als
bei vollen veränderlichen Variablen soll dabei jede Variable nur
höchstens einmal gesetzt werden können.

Ein möglicher Primitivoperator zum Umgang damit könnte zum Beispiel wie

    set var val

aussehen. Sofern die Variable noch nicht gesetzt war, wird ihr Wert auf
val festgesetzt. In jedem Fall wird der (möglicherweise erstmal
gesetzte) Wert der Variablen zurückgegeben.

Mit monotonen Setzungen sollte man eine "zufällige Funktion"

    random :: Nat -> Float

implementieren können. Bei der ersten Auswertung von random n wird
(irgendwie) eine Zufallszahl bestimmt. Weitere Auswertungen von random n
sollen dieselbe Zufallszahl zurückliefern.

Erlaubt man monotone Setzungen, so ist die Addition nicht mehr
kommutativ: Denn

    set var 0 + set var 1

wird zu 0 + 0 = 0 evaluieren, während

    set var 1 + set var 0

zu 1 + 1 = 2 evaluieren wird. Allerdings lässt sich das intern nicht
feststellen! Der Bool

    set var 0 + set var 1 == set var 1 + set var 0

ist True (unabhängig davon, in welcher Reihenfolge die vier Setzungen
ausgewertet werden).


=== Universelle Maschine

http://jdh.hamkins.org/a-program-that-accepts-any-desired-finite-set-in-the-right-universe/

Es gibt eine Turingmaschine M, sodass für jede Funktion f : N --> N (auch für
die unberechenbaren) ein Modell von PA (oder ZFC) existiert, sodass für alle
natürlichen Zahlen n gilt, dass in U die Maschine M bei Eingabe von n hält und
das Ergebnis f(n) liefert.


=== Obfuscation

https://www.quantamagazine.org/in-cryptography-advances-in-program-obfuscation-20140130
http://eprint.iacr.org/2013/451.pdf
http://eprint.iacr.org/2013/454.pdf


=== Wie mit Variablennamen umgehen?

* Locally Nameless: Namen für freie Variablen, Indizes für gebundene.
  https://www.chargueraud.org/research/2009/ln/main.pdf

* Nominal Approach. ??
  https://www.seas.upenn.edu/~sweirich/papers/nominal-coq/lfmtp06.pdf

* Higher Order Abstract Syntax.

  Problem: Exotic Terms.

  Eine Lösung für dieses Problem: http://adam.chlipala.net/papers/PhoasICFP08/PhoasICFP08.pdf
  Var : V → Term(V)
  App : Term(V) → Term(V) → Term(V)
  Abs : (V → Term(V)) → Term(V),
  dann Term = (∀(V : *). Term(V)).

* Nominal Sets (Mengen mit Perm(A)-Wirkung, wobei A die Menge der
  Variablennamen ist):
  https://www.cl.cam.ac.uk/~amp12/talks/MGS2011_nominal_sets_slides.pdf


=== Ableitungen von Turingmaschinen

http://therisingsea.org/notes/talk-beida-tm-2018.pdf
